{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{},"source":["cv2.imshow terminal\n","xhost + "]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":26,"status":"ok","timestamp":1670588587469,"user":{"displayName":"みまみま","userId":"08438286750981985853"},"user_tz":-540},"id":"3VfEcVSNPWiL","outputId":"981789c2-d8b6-497f-9b19-bcb7d5fbb789"},"outputs":[{"name":"stdout","output_type":"stream","text":["nvcc: NVIDIA (R) Cuda compiler driver\n","Copyright (c) 2005-2021 NVIDIA Corporation\n","Built on Sun_Feb_14_21:12:58_PST_2021\n","Cuda compilation tools, release 11.2, V11.2.152\n","Build cuda_11.2.r11.2/compiler.29618528_0\n"]}],"source":["!nvcc --version"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5131,"status":"ok","timestamp":1670588592590,"user":{"displayName":"みまみま","userId":"08438286750981985853"},"user_tz":-540},"id":"xauIBijEPjJO","outputId":"f9e77cbd-7847-49e0-e4b8-947a33f01721"},"outputs":[{"name":"stdout","output_type":"stream","text":["1.13.0+cu116\n","11.6\n"]}],"source":["!python -c 'import torch; print(torch.__version__) '\n","!python -c \"import torch; print(torch.version.cuda)\""]},{"cell_type":"markdown","metadata":{"id":"KndWvALzfoG_"},"source":["# YOLOX 依存パッケージインストール(YOLOX Dependent Package Install)"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1794,"status":"ok","timestamp":1670588594379,"user":{"displayName":"みまみま","userId":"08438286750981985853"},"user_tz":-540},"id":"YpviPxKHfh59","outputId":"48268e75-bd39-4d9c-a8d2-30bb3657cfa8"},"outputs":[{"name":"stdout","output_type":"stream","text":["Cloning into 'YOLOX'...\n","remote: Enumerating objects: 1764, done.\u001b[K\n","remote: Counting objects: 100% (41/41), done.\u001b[K\n","remote: Compressing objects: 100% (35/35), done.\u001b[K\n","remote: Total 1764 (delta 13), reused 19 (delta 4), pack-reused 1723\u001b[K\n","Receiving objects: 100% (1764/1764), 6.86 MiB | 3.18 MiB/s, done.\n","Resolving deltas: 100% (1033/1033), done.\n"]}],"source":["!git clone https://github.com/Megvii-BaseDetection/YOLOX"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":42565,"status":"ok","timestamp":1670588636935,"user":{"displayName":"みまみま","userId":"08438286750981985853"},"user_tz":-540},"id":"maY7_U3gLhQA","outputId":"f215a577-ceee-434c-af90-9eca9000051d"},"outputs":[{"name":"stdout","output_type":"stream","text":["/root/YOLOX\n","Collecting pip\n","  Using cached pip-22.3.1-py3-none-any.whl (2.1 MB)\n","Installing collected packages: pip\n","  Attempting uninstall: pip\n","    Found existing installation: pip 20.0.2\n","    Not uninstalling pip at /usr/lib/python3/dist-packages, outside environment /usr\n","    Can't uninstall 'pip'. No files were found to uninstall.\n","Successfully installed pip-22.3.1\n","Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 2)) (1.20.3)\n","Requirement already satisfied: torch>=1.7 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 3)) (1.13.0+cu116)\n","Requirement already satisfied: opencv_python in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 4)) (4.6.0.66)\n","Requirement already satisfied: loguru in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 5)) (0.6.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 6)) (4.64.1)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 7)) (0.14.0+cu116)\n","Requirement already satisfied: thop in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 8)) (0.1.1.post2209072238)\n","Requirement already satisfied: ninja in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 9)) (1.11.1)\n","Requirement already satisfied: tabulate in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 10)) (0.9.0)\n","Processing /root/.cache/pip/wheels/3e/08/ac/58126fe59992032701437336493f6132e1b72381a62d00b595/pycocotools-2.0.6-cp38-cp38-linux_x86_64.whl\n","Requirement already satisfied: onnx==1.8.1 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 15)) (1.8.1)\n","Requirement already satisfied: onnxruntime==1.8.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 16)) (1.8.0)\n","Requirement already satisfied: onnx-simplifier==0.3.5 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 17)) (0.3.5)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch>=1.7->-r requirements.txt (line 3)) (4.4.0)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.8/dist-packages (from torchvision->-r requirements.txt (line 7)) (9.2.0)\n","Requirement already satisfied: requests in /usr/lib/python3/dist-packages (from torchvision->-r requirements.txt (line 7)) (2.22.0)\n","Requirement already satisfied: matplotlib>=2.1.0 in /usr/local/lib/python3.8/dist-packages (from pycocotools>=2.0.2->-r requirements.txt (line 14)) (3.6.2)\n","Requirement already satisfied: six in /usr/lib/python3/dist-packages (from onnx==1.8.1->-r requirements.txt (line 15)) (1.14.0)\n","Requirement already satisfied: protobuf in /usr/local/lib/python3.8/dist-packages (from onnx==1.8.1->-r requirements.txt (line 15)) (3.20.3)\n","Requirement already satisfied: flatbuffers in /usr/local/lib/python3.8/dist-packages (from onnxruntime==1.8.0->-r requirements.txt (line 16)) (22.12.6)\n","Requirement already satisfied: onnxoptimizer>=0.2.5 in /usr/local/lib/python3.8/dist-packages (from onnx-simplifier==0.3.5->-r requirements.txt (line 17)) (0.3.2)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->-r requirements.txt (line 14)) (1.0.6)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->-r requirements.txt (line 14)) (4.38.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->-r requirements.txt (line 14)) (0.11.0)\n","Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->-r requirements.txt (line 14)) (3.0.9)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->-r requirements.txt (line 14)) (22.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->-r requirements.txt (line 14)) (1.4.4)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->-r requirements.txt (line 14)) (2.8.2)\n","Installing collected packages: pycocotools\n","  Attempting uninstall: pycocotools\n","    Found existing installation: pycocotools 2.0\n","    Uninstalling pycocotools-2.0:\n","      Successfully uninstalled pycocotools-2.0\n","Successfully installed pycocotools-2.0.6\n","Non-user install because site-packages writeable\n","Created temporary directory: /tmp/pip-ephem-wheel-cache-zaxb8rij\n","Created temporary directory: /tmp/pip-req-tracker-_hs86ggh\n","Initialized build tracking at /tmp/pip-req-tracker-_hs86ggh\n","Created build tracker: /tmp/pip-req-tracker-_hs86ggh\n","Entered build tracker: /tmp/pip-req-tracker-_hs86ggh\n","Created temporary directory: /tmp/pip-install-m5obqk0d\n","Obtaining file:///root/YOLOX\n","  Added file:///root/YOLOX to build tracker '/tmp/pip-req-tracker-_hs86ggh'\n","    Running setup.py (path:/root/YOLOX/setup.py) egg_info for package from file:///root/YOLOX\n","    Running command python setup.py egg_info\n","    running egg_info\n","    writing yolox.egg-info/PKG-INFO\n","    writing dependency_links to yolox.egg-info/dependency_links.txt\n","    writing requirements to yolox.egg-info/requires.txt\n","    writing top-level names to yolox.egg-info/top_level.txt\n","    reading manifest file 'yolox.egg-info/SOURCES.txt'\n","    reading manifest template 'MANIFEST.in'\n","    warning: no files found matching '*.cu' under directory 'yolox'\n","    warning: no files found matching '*.cuh' under directory 'yolox'\n","    warning: no files found matching '*.cc' under directory 'yolox'\n","    writing manifest file 'yolox.egg-info/SOURCES.txt'\n","  Source in /root/YOLOX has version 0.3.0, which satisfies requirement yolox==0.3.0 from file:///root/YOLOX\n","  Removed yolox==0.3.0 from file:///root/YOLOX from build tracker '/tmp/pip-req-tracker-_hs86ggh'\n","Requirement already satisfied: loguru in /usr/local/lib/python3.8/dist-packages (from yolox==0.3.0) (0.6.0)\n","Requirement already satisfied: ninja in /usr/local/lib/python3.8/dist-packages (from yolox==0.3.0) (1.11.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from yolox==0.3.0) (1.20.3)\n","Requirement already satisfied: onnx-simplifier==0.3.5 in /usr/local/lib/python3.8/dist-packages (from yolox==0.3.0) (0.3.5)\n","Requirement already satisfied: onnx==1.8.1 in /usr/local/lib/python3.8/dist-packages (from yolox==0.3.0) (1.8.1)\n","Requirement already satisfied: onnxruntime==1.8.0 in /usr/local/lib/python3.8/dist-packages (from yolox==0.3.0) (1.8.0)\n","Requirement already satisfied: opencv_python in /usr/local/lib/python3.8/dist-packages (from yolox==0.3.0) (4.6.0.66)\n","Requirement already satisfied: pycocotools>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from yolox==0.3.0) (2.0.6)\n","Requirement already satisfied: tabulate in /usr/local/lib/python3.8/dist-packages (from yolox==0.3.0) (0.9.0)\n","Requirement already satisfied: thop in /usr/local/lib/python3.8/dist-packages (from yolox==0.3.0) (0.1.1.post2209072238)\n","Requirement already satisfied: torch>=1.7 in /usr/local/lib/python3.8/dist-packages (from yolox==0.3.0) (1.13.0+cu116)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.8/dist-packages (from yolox==0.3.0) (0.14.0+cu116)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from yolox==0.3.0) (4.64.1)\n","Requirement already satisfied: onnxoptimizer>=0.2.5 in /usr/local/lib/python3.8/dist-packages (from onnx-simplifier==0.3.5->yolox==0.3.0) (0.3.2)\n","Requirement already satisfied: protobuf>=3.7.0 in /usr/local/lib/python3.8/dist-packages (from onnx-simplifier==0.3.5->yolox==0.3.0) (3.20.3)\n","Requirement already satisfied: six in /usr/lib/python3/dist-packages (from onnx==1.8.1->yolox==0.3.0) (1.14.0)\n","Requirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.8/dist-packages (from onnx==1.8.1->yolox==0.3.0) (4.4.0)\n","Requirement already satisfied: flatbuffers in /usr/local/lib/python3.8/dist-packages (from onnxruntime==1.8.0->yolox==0.3.0) (22.12.6)\n","Requirement already satisfied: matplotlib>=2.1.0 in /usr/local/lib/python3.8/dist-packages (from pycocotools>=2.0.2->yolox==0.3.0) (3.6.2)\n","Requirement already satisfied: requests in /usr/lib/python3/dist-packages (from torchvision->yolox==0.3.0) (2.22.0)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.8/dist-packages (from torchvision->yolox==0.3.0) (9.2.0)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->yolox==0.3.0) (2.8.2)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->yolox==0.3.0) (1.0.6)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->yolox==0.3.0) (4.38.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->yolox==0.3.0) (1.4.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->yolox==0.3.0) (22.0)\n","Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->yolox==0.3.0) (3.0.9)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->yolox==0.3.0) (0.11.0)\n","Installing collected packages: yolox\n","  Attempting uninstall: yolox\n","    Found existing installation: yolox 0.3.0\n","    Not sure how to uninstall: yolox 0.3.0 - Check: /root/YOLOX\n","    Can't uninstall 'yolox'. No files were found to uninstall.\n","  Running setup.py develop for yolox\n","    Running command /usr/bin/python3 -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/root/YOLOX/setup.py'\"'\"'; __file__='\"'\"'/root/YOLOX/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' develop --no-deps\n","    running develop\n","    running egg_info\n","    writing yolox.egg-info/PKG-INFO\n","    writing dependency_links to yolox.egg-info/dependency_links.txt\n","    writing requirements to yolox.egg-info/requires.txt\n","    writing top-level names to yolox.egg-info/top_level.txt\n","    reading manifest file 'yolox.egg-info/SOURCES.txt'\n","    reading manifest template 'MANIFEST.in'\n","    warning: no files found matching '*.cu' under directory 'yolox'\n","    warning: no files found matching '*.cuh' under directory 'yolox'\n","    warning: no files found matching '*.cc' under directory 'yolox'\n","    writing manifest file 'yolox.egg-info/SOURCES.txt'\n","    running build_ext\n","    building 'yolox.layers.fast_cocoeval' extension\n","    Emitting ninja build file /root/YOLOX/build/temp.linux-x86_64-3.8/build.ninja...\n","    Compiling objects...\n","    Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n","    [1/1] c++ -MMD -MF /root/YOLOX/build/temp.linux-x86_64-3.8/yolox/layers/cocoeval/cocoeval.o.d -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -Iyolox/layers/cocoeval -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/include/python3.8 -c -c /root/YOLOX/yolox/layers/cocoeval/cocoeval.cpp -o /root/YOLOX/build/temp.linux-x86_64-3.8/yolox/layers/cocoeval/cocoeval.o -O3 -std=c++14 -g -Wno-reorder -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=fast_cocoeval -D_GLIBCXX_USE_CXX11_ABI=0\n","    x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 /root/YOLOX/build/temp.linux-x86_64-3.8/yolox/layers/cocoeval/cocoeval.o -L/usr/local/lib/python3.8/dist-packages/torch/lib -lc10 -ltorch -ltorch_cpu -ltorch_python -o build/lib.linux-x86_64-3.8/yolox/layers/fast_cocoeval.cpython-38-x86_64-linux-gnu.so\n","    copying build/lib.linux-x86_64-3.8/yolox/layers/fast_cocoeval.cpython-38-x86_64-linux-gnu.so -> yolox/layers\n","    Creating /usr/local/lib/python3.8/dist-packages/yolox.egg-link (link to .)\n","    yolox 0.3.0 is already the active version in easy-install.pth\n","\n","    Installed /root/YOLOX\n","Successfully installed yolox\n","Cleaning up...\n","Removed build tracker: '/tmp/pip-req-tracker-_hs86ggh'\n"]}],"source":["%cd /root/YOLOX\n","\n","!pip install -U pip && pip install -r requirements.txt\n","!pip install -v -e .  "]},{"cell_type":"markdown","metadata":{"id":"k1t1Hb74iIZo"},"source":["# PyCocoToolsインストール(PyCocoTools Install)"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18665,"status":"ok","timestamp":1670588655593,"user":{"displayName":"みまみま","userId":"08438286750981985853"},"user_tz":-540},"id":"YCje1A8mhtLy","outputId":"e290c84b-2fab-4b44-f2d6-3ac9d0cb7e3e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting cython\n","  Using cached Cython-0.29.32-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (1.9 MB)\n","Installing collected packages: cython\n","Successfully installed cython-0.29.32\n","Collecting git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI\n","  Cloning https://github.com/cocodataset/cocoapi.git to /tmp/pip-req-build-bimfdpft\n","  Running command git clone -q https://github.com/cocodataset/cocoapi.git /tmp/pip-req-build-bimfdpft\n","Requirement already satisfied: cython>=0.27.3 in /usr/local/lib/python3.8/dist-packages (from pycocotools==2.0) (0.29.32)\n","Requirement already satisfied: matplotlib>=2.1.0 in /usr/local/lib/python3.8/dist-packages (from pycocotools==2.0) (3.6.2)\n","Requirement already satisfied: setuptools>=18.0 in /usr/lib/python3/dist-packages (from pycocotools==2.0) (45.2.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (1.4.4)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (9.2.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (22.0)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (2.8.2)\n","Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (3.0.9)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (4.38.0)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (1.0.6)\n","Requirement already satisfied: numpy>=1.19 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (1.20.3)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (0.11.0)\n","Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7->matplotlib>=2.1.0->pycocotools==2.0) (1.14.0)\n","Building wheels for collected packages: pycocotools\n","  Building wheel for pycocotools (setup.py) ... \u001b[?25ldone\n","\u001b[?25h  Created wheel for pycocotools: filename=pycocotools-2.0-cp38-cp38-linux_x86_64.whl size=421088 sha256=4af960ac026cd4e7d70bff7e468f037d8ef08e139a5216a591bb83326bc17a82\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-62rd9e5t/wheels/56/da/49/cb71a7c450b59588934077f431100c05fbde50646ee84a8d40\n","Successfully built pycocotools\n","\u001b[31mERROR: yolox 0.3.0 has requirement pycocotools>=2.0.2, but you'll have pycocotools 2.0 which is incompatible.\u001b[0m\n","Installing collected packages: pycocotools\n","  Attempting uninstall: pycocotools\n","    Found existing installation: pycocotools 2.0.6\n","    Uninstalling pycocotools-2.0.6:\n","      Successfully uninstalled pycocotools-2.0.6\n","Successfully installed pycocotools-2.0\n"]}],"source":["!pip install cython\n","!pip install 'git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI'"]},{"cell_type":"markdown","metadata":{"id":"iWp26peevulP"},"source":["# データセットダウンロード(Download Dataset)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":61733,"status":"ok","timestamp":1670588717286,"user":{"displayName":"みまみま","userId":"08438286750981985853"},"user_tz":-540},"id":"NSZzrY_ZPJZV","outputId":"764c71ce-311e-4453-8602-9a060695b974"},"outputs":[],"source":["\"\"\"from google.colab import drive\n","drive.mount('/content/drive')\n","%cd /content/\"\"\""]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":438,"status":"ok","timestamp":1670588717703,"user":{"displayName":"みまみま","userId":"08438286750981985853"},"user_tz":-540},"id":"XZQxPDFFPLas"},"outputs":[],"source":["!cp /content/drive/MyDrive/datav5.zip ./"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":380,"status":"ok","timestamp":1670588718076,"user":{"displayName":"みまみま","userId":"08438286750981985853"},"user_tz":-540},"id":"KqJJ2qOKPPzh","outputId":"b22b2b23-ea11-4364-d79a-c9a6b6f38c45"},"outputs":[],"source":["!unzip datav5.zip"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":30,"status":"ok","timestamp":1670588718077,"user":{"displayName":"みまみま","userId":"08438286750981985853"},"user_tz":-540},"id":"frzsMeeetO1y","outputId":"6b792e21-4319-4148-e5c2-a5d18463c3bf"},"outputs":[{"name":"stdout","output_type":"stream","text":["/root/ML\n"]}],"source":["%cd /root/ML\n","use_sample_image = False\n","\n","if use_sample_image:\n","    !git clone https://github.com/Kazuhito00/YOLOX-Colaboratory-Training-Sample.git"]},{"cell_type":"markdown","metadata":{"id":"NC3Frlnzz5eC"},"source":["# 学習/検証データ分割(Train/Validation split data)"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["/root/ML\n"]}],"source":["%cd /root/ML"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1670588718077,"user":{"displayName":"みまみま","userId":"08438286750981985853"},"user_tz":-540},"id":"pkp7yRJPv0_1"},"outputs":[],"source":["#folk_dataset\n","import os\n","\n","# 独自のデータを使用する場合は、パスを指定してください\n","# Please fill in the path if you want to use your own data\n","if use_sample_image:\n","    dataset_directory = 'YOLOX-Colaboratory-Training-Sample/02.annotation_data'\n","else:\n","    dataset_directory = '/root/ML/data_folk'\n","\n","# 学習/検証データパス(train/validation data path)\n","train_directory = './train_folk'\n","validation_directory = './validation_folk'\n","\n","# 学習データ格納ディレクトリ作成(Create training data storage directory)\n","os.makedirs(train_directory, exist_ok=True)\n","# 検証データ格納ディレクトリ作成(Create verification data storage directory)\n","os.makedirs(validation_directory, exist_ok=True)"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[],"source":["#spoon_dataset\n","import os\n","\n","# 独自のデータを使用する場合は、パスを指定してください\n","# Please fill in the path if you want to use your own data\n","if use_sample_image:\n","    dataset_directory = 'YOLOX-Colaboratory-Training-Sample/02.annotation_data'\n","else:\n","    dataset_directory = '/root/ML/data_spoon'\n","\n","# 学習/検証データパス(train/validation data path)\n","train_directory = '/root/ML/train_spoon'\n","validation_directory = '/root/ML/validation_spoon'\n","\n","# 学習データ格納ディレクトリ作成(Create training data storage directory)\n","os.makedirs(train_directory, exist_ok=True)\n","# 検証データ格納ディレクトリ作成(Create verification data storage directory)\n","os.makedirs(validation_directory, exist_ok=True)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#knife_dataset\n","import os\n","\n","# 独自のデータを使用する場合は、パスを指定してください\n","# Please fill in the path if you want to use your own data\n","if use_sample_image:\n","    dataset_directory = 'YOLOX-Colaboratory-Training-Sample/02.annotation_data'\n","else:\n","    dataset_directory = '/root/ML/data_knife'\n","\n","# 学習/検証データパス(train/validation data path)\n","train_directory = './train_knife'\n","validation_directory = './validation_knife'\n","\n","# 学習データ格納ディレクトリ作成(Create training data storage directory)\n","os.makedirs(train_directory, exist_ok=True)\n","# 検証データ格納ディレクトリ作成(Create verification data storage directory)\n","os.makedirs(validation_directory, exist_ok=True)"]},{"cell_type":"code","execution_count":20,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1670588718078,"user":{"displayName":"みまみま","userId":"08438286750981985853"},"user_tz":-540},"id":"BJieAq9IywqQ"},"outputs":[],"source":["import glob\n","import shutil\n","import random\n","\n","# 学習データの割合(Percentage of training data)\n","train_ratio = 0.8\n","\n","# コピー元ファイルリスト取得(Get copy source file list)\n","annotation_list = sorted(glob.glob(dataset_directory + '/*.xml'))\n","image_list = sorted(glob.glob(dataset_directory + '/*.jpg'))\n","\n","file_num = len(annotation_list)\n","\n","# インデックスシャッフル(shuffle)\n","index_list = list(range(file_num - 1))\n","random.shuffle(index_list)\n","\n","for count, index in enumerate(index_list):\n","    if count < int(file_num * train_ratio):\n","        # 学習用データ(Training Data)\n","        shutil.copy2(annotation_list[index], train_directory)\n","        shutil.copy2(image_list[index], train_directory)\n","    else:\n","        # 検証用データ(Validation Data)\n","        shutil.copy2(annotation_list[index], validation_directory)\n","        shutil.copy2(image_list[index], validation_directory)"]},{"cell_type":"markdown","metadata":{"id":"ACKapHgx_d4Q"},"source":["# Pascal VOC形式 を MS COCO形式へ変換(Convert Pascal VOC format to MS COCO format)"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1031,"status":"ok","timestamp":1670588719103,"user":{"displayName":"みまみま","userId":"08438286750981985853"},"user_tz":-540},"id":"qKGpaUik_c9m","outputId":"7b44b885-06e7-4840-fdfc-20a8eb7286d2"},"outputs":[{"name":"stdout","output_type":"stream","text":["fatal: destination path 'convert_voc_to_coco' already exists and is not an empty directory.\n"]}],"source":["!git clone https://github.com/Kazuhito00/convert_voc_to_coco.git"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of xml files: 0\n","Convert XML to JSON: 0it [00:00, ?it/s]\n","{}\n","Success: train_folk/train_annotations.json\n","Number of xml files: 0\n","Convert XML to JSON: 0it [00:00, ?it/s]\n","{}\n","Success: validation_folk/validation_annotations.json\n"]}],"source":["#folk_dataset\n","!python3 convert_voc_to_coco/convert_voc_to_coco.py \\\n","    train train_folk/train_annotations.json \\\n","    --start_image_id=0\n","!python3 convert_voc_to_coco/convert_voc_to_coco.py \\\n","    validation validation_folk/validation_annotations.json \\\n","    --start_image_id=10000000"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of xml files: 224\n","Convert XML to JSON: 100%|█████████████████| 224/224 [00:00<00:00, 33045.76it/s]\n","{'top_spoon': 112, 'handle_folk': 110}\n","Success: train_spoon/train_annotations.json\n","Number of xml files: 55\n","Convert XML to JSON: 100%|███████████████████| 55/55 [00:00<00:00, 30923.15it/s]\n","{'handle_folk': 27, 'top_spoon': 26}\n","Success: validation_spoon/validation_annotations.json\n"]}],"source":["#spoon_dataset\n","!python3 convert_voc_to_coco/convert_voc_to_coco.py \\\n","    train_spoon train_spoon/train_annotations.json \\\n","    --start_image_id=0\n","!python3 convert_voc_to_coco/convert_voc_to_coco.py \\\n","    validation_spoon validation_spoon/validation_annotations.json \\\n","    --start_image_id=10000000"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#knife_dataset\n","!python3 convert_voc_to_coco/convert_voc_to_coco.py \\\n","    train train_knife/train_annotations.json \\\n","    --start_image_id=0\n","!python3 convert_voc_to_coco/convert_voc_to_coco.py \\\n","    validation validation_knife/validation_annotations.json \\\n","    --start_image_id=10000000"]},{"cell_type":"markdown","metadata":{"id":"wJ9ytPB90pJP"},"source":["# 学習データディレクトリ準備(Training data directory preparation)"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":930,"status":"ok","timestamp":1670588720433,"user":{"displayName":"みまみま","userId":"08438286750981985853"},"user_tz":-540},"id":"IccyvWRpDZGL"},"outputs":[],"source":["#folk_dataset\n","!mkdir dataset_folk\n","!mkdir dataset_folk/images\n","!mkdir dataset_folk/images/train2017\n","!mkdir dataset_folk/images/val2017\n","!mkdir dataset_folk/annotations\n","\n","!cp -rf train_folk/*.jpg dataset_folk/images/train2017\n","!cp -rf validation_folk/*.jpg dataset_folk/images/val2017\n","!cp -rf train_folk/train_annotations.json dataset_folk/annotations\n","!cp -rf validation_folk/validation_annotations.json dataset_folk/annotations"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["mkdir: cannot create directory ‘dataset_spoon’: File exists\n","mkdir: cannot create directory ‘dataset_spoon/images’: File exists\n","mkdir: cannot create directory ‘dataset_spoon/images/train2017’: File exists\n","mkdir: cannot create directory ‘dataset_spoon/images/val2017’: File exists\n","mkdir: cannot create directory ‘dataset_spoon/annotations’: File exists\n"]}],"source":["#spoon_dataset\n","!mkdir dataset_spoon\n","!mkdir dataset_spoon/images\n","!mkdir dataset_spoon/images/train2017\n","!mkdir dataset_spoon/images/val2017\n","!mkdir dataset_spoon/annotations\n","\n","!cp -rf train_spoon/*.jpg dataset_spoon/images/train2017\n","!cp -rf validation_spoon/*.jpg dataset_spoon/images/val2017\n","!cp -rf train_spoon/train_annotations.json dataset_spoon/annotations\n","!cp -rf validation_spoon/validation_annotations.json dataset_spoon/annotations"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#knife_dataset\n","!mkdir dataset_knife\n","!mkdir dataset_knife/images\n","!mkdir dataset_knife/images/train2017\n","!mkdir dataset_knife/images/val2017\n","!mkdir dataset_knife/annotations\n","\n","!cp -rf train_knife/*.jpg dataset_knife/images/train2017\n","!cp -rf validation_knife/*.jpg dataset_knife/images/val2017\n","!cp -rf train_knife/train_annotations.json dataset_knife/annotations\n","!cp -rf validation_knife/validation_annotations.json dataset_knife/annotations"]},{"cell_type":"markdown","metadata":{"id":"CnUirebA1a__"},"source":["# コンフィグコピー\n","<!--\n","![image](https://user-images.githubusercontent.com/37477845/135283504-254ea817-345e-4665-828a-4c6034645ed1.png)\n","-->\n"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":15,"status":"ok","timestamp":1670588720434,"user":{"displayName":"みまみま","userId":"08438286750981985853"},"user_tz":-540},"id":"gzlWZMuSPUly"},"outputs":[],"source":["if use_sample_image:\n","    !cp /content/YOLOX-Colaboratory-Training-Sample/03.config/nano.py /content/YOLOX"]},{"cell_type":"markdown","metadata":{"id":"vVvBXq4e2ydb"},"source":["# モデル訓練"]},{"cell_type":"code","execution_count":24,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1670588720435,"user":{"displayName":"みまみま","userId":"08438286750981985853"},"user_tz":-540},"id":"hobMWbgPUUrq","outputId":"95755616-e410-4056-9245-9bb5171031f1"},"outputs":[{"name":"stdout","output_type":"stream","text":["/root/YOLOX\n"]}],"source":["%cd /root/YOLOX"]},{"cell_type":"markdown","metadata":{"id":"MuoY2aHcf04N"},"source":["yolox_s"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Overwriting yolox_s.py\n"]}],"source":["%%writefile yolox_s.py\n","#!/usr/bin/env python3\n","# -*- coding:utf-8 -*-\n","# Copyright (c) Megvii, Inc. and its affiliates.\n","\n","import os\n","\n","from yolox.exp import Exp as MyExp\n","\n","\n","class Exp(MyExp):\n","    def __init__(self):\n","        super(Exp, self).__init__()\n","        self.depth = 0.33\n","        self.width = 0.50\n","        self.max_epoch = 20\n","        self.exp_name = os.path.split(os.path.realpath(__file__))[1].split(\".\")[0]\n","\n","        self.data_dir = \"/root/ML/dataset_spoon/images\"\n","        self.train_ann = \"/root/ML/dataset_spoon/annotations/train_annotations.json\"\n","        self.val_ann = \"/root/ML/dataset_spoon/annotations/validation_annotations.json\"\n","\n","        self.num_classes = 2\n","\n","        self.eval_interval = 1\n"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":284,"status":"ok","timestamp":1670588789334,"user":{"displayName":"みまみま","userId":"08438286750981985853"},"user_tz":-540},"id":"lJEIt55Tf0iX","outputId":"bf730010-d692-453a-eef1-1ebc830f359e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Overwriting yolox_nano.py\n"]}],"source":["%%writefile yolox_nano.py\n","#!/usr/bin/env python3\n","# -*- coding:utf-8 -*-\n","# Copyright (c) Megvii, Inc. and its affiliates.\n","\n","import os\n","\n","import torch.nn as nn\n","\n","from yolox.exp import Exp as MyExp\n","\n","\n","class Exp(MyExp):\n","    def __init__(self):\n","        super(Exp, self).__init__()\n","        self.depth = 0.33\n","        self.width = 0.25\n","        self.input_size = (416, 416)\n","        self.random_size = (10, 20)\n","        self.mosaic_scale = (0.5, 1.5)\n","        self.test_size = (416, 416)\n","        self.mosaic_prob = 0.5\n","        self.enable_mixup = False\n","        self.exp_name = os.path.split(os.path.realpath(__file__))[1].split(\".\")[0]\n","        \n","        self.num_classes = 2\n","        self.max_epoch = 20\n","        self.data_num_worker = 4\n","        self.eval_interval = 1\n","\n","    def get_model(self, sublinear=False):\n","\n","        def init_yolo(M):\n","            for m in M.modules():\n","                if isinstance(m, nn.BatchNorm2d):\n","                    m.eps = 1e-3\n","                    m.momentum = 0.03\n","        if \"model\" not in self.__dict__:\n","            from yolox.models import YOLOX, YOLOPAFPN, YOLOXHead\n","            in_channels = [256, 512, 1024]\n","            # NANO model use depthwise = True, which is Main difference.\n","            backbone = YOLOPAFPN(self.depth, self.width, in_channels=in_channels, depthwise=True)\n","            head = YOLOXHead(self.num_classes, self.width, in_channels=in_channels, depthwise=True)\n","            self.model = YOLOX(backbone, head)\n","\n","        self.model.apply(init_yolo)                      \n","        self.model.head.initialize_biases(1e-2)\n","        return self.model"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6201,"status":"ok","timestamp":1670588798983,"user":{"displayName":"みまみま","userId":"08438286750981985853"},"user_tz":-540},"id":"ykzClTsh1ZDA","outputId":"299d051c-68b3-47c9-9a9b-19d63fa915ac"},"outputs":[{"name":"stdout","output_type":"stream","text":["/root/YOLOX\n","--2022-12-23 19:18:51--  https://github.com/Megvii-BaseDetection/storage/releases/download/0.0.1/yolox_s.pth\n","Resolving github.com (github.com)... 20.27.177.113\n","Connecting to github.com (github.com)|20.27.177.113|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/388351473/0b307dd4-bddb-4cfe-a863-1d19afb5598a?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20221223%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20221223T101851Z&X-Amz-Expires=300&X-Amz-Signature=d0d8e7635efabd0cac35c85bba892f429200f81c7724afe9732898829d0fafe0&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=388351473&response-content-disposition=attachment%3B%20filename%3Dyolox_s.pth&response-content-type=application%2Foctet-stream [following]\n","--2022-12-23 19:18:51--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/388351473/0b307dd4-bddb-4cfe-a863-1d19afb5598a?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20221223%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20221223T101851Z&X-Amz-Expires=300&X-Amz-Signature=d0d8e7635efabd0cac35c85bba892f429200f81c7724afe9732898829d0fafe0&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=388351473&response-content-disposition=attachment%3B%20filename%3Dyolox_s.pth&response-content-type=application%2Foctet-stream\n","Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.111.133, 185.199.109.133, 185.199.108.133, ...\n","Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.111.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 72050245 (69M) [application/octet-stream]\n","Saving to: ‘yolox_s.pth’\n","\n","yolox_s.pth         100%[===================>]  68.71M  7.25MB/s    in 7.6s    \n","\n","2022-12-23 19:19:00 (9.01 MB/s) - ‘yolox_s.pth’ saved [72050245/72050245]\n","\n"]}],"source":["%cd /root/YOLOX\n","!wget https://github.com/Megvii-BaseDetection/storage/releases/download/0.0.1/yolox_s.pth"]},{"cell_type":"code","execution_count":25,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":258344,"status":"ok","timestamp":1670589058318,"user":{"displayName":"みまみま","userId":"08438286750981985853"},"user_tz":-540},"id":"qZDXBpaY22lN","outputId":"ff90b23d-9147-4e9a-c144-2c049c3ea0ef"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[32m2023-01-13 17:08:13.260\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.launch\u001b[0m:\u001b[36m_distributed_worker\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1mRank 1 initialization finished.\u001b[0m\n","\u001b[32m2023-01-13 17:08:13.261\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.launch\u001b[0m:\u001b[36m_distributed_worker\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1mRank 0 initialization finished.\u001b[0m\n","\u001b[32m2023-01-13 17:08:15.646\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.utils.setup_env\u001b[0m:\u001b[36mconfigure_omp\u001b[0m:\u001b[36m41\u001b[0m - \u001b[1m\n","***************************************************************\n","We set `OMP_NUM_THREADS` for each process to 1 to speed up.\n","please further tune the variable for optimal performance.\n","***************************************************************\u001b[0m\n","\u001b[32m2023-01-13 17:08:15\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m130\u001b[0m - \u001b[1margs: Namespace(batch_size=2, cache=False, ckpt='/root/YOLOX/yolox_s.pth', devices=2, dist_backend='nccl', dist_url=None, exp_file='/root/YOLOX/yolox_s.py', experiment_name='yolox_s', fp16=True, logger='tensorboard', machine_rank=0, name=None, num_machines=1, occupy=True, opts=[], resume=False, start_epoch=None)\u001b[0m\n","\u001b[32m2023-01-13 17:08:15\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m131\u001b[0m - \u001b[1mexp value:\n","╒═══════════════════╤══════════════════════════════════════════════════════════════════╕\n","│ keys              │ values                                                           │\n","╞═══════════════════╪══════════════════════════════════════════════════════════════════╡\n","│ seed              │ None                                                             │\n","├───────────────────┼──────────────────────────────────────────────────────────────────┤\n","│ output_dir        │ './YOLOX_outputs'                                                │\n","├───────────────────┼──────────────────────────────────────────────────────────────────┤\n","│ print_interval    │ 10                                                               │\n","├───────────────────┼──────────────────────────────────────────────────────────────────┤\n","│ eval_interval     │ 1                                                                │\n","├───────────────────┼──────────────────────────────────────────────────────────────────┤\n","│ num_classes       │ 2                                                                │\n","├───────────────────┼──────────────────────────────────────────────────────────────────┤\n","│ depth             │ 0.33                                                             │\n","├───────────────────┼──────────────────────────────────────────────────────────────────┤\n","│ width             │ 0.5                                                              │\n","├───────────────────┼──────────────────────────────────────────────────────────────────┤\n","│ act               │ 'silu'                                                           │\n","├───────────────────┼──────────────────────────────────────────────────────────────────┤\n","│ data_num_workers  │ 4                                                                │\n","├───────────────────┼──────────────────────────────────────────────────────────────────┤\n","│ input_size        │ (640, 640)                                                       │\n","├───────────────────┼──────────────────────────────────────────────────────────────────┤\n","│ multiscale_range  │ 5                                                                │\n","├───────────────────┼──────────────────────────────────────────────────────────────────┤\n","│ data_dir          │ '/root/ML/dataset_spoon/images'                                  │\n","├───────────────────┼──────────────────────────────────────────────────────────────────┤\n","│ train_ann         │ '/root/ML/dataset_spoon/annotations/train_annotations.json'      │\n","├───────────────────┼──────────────────────────────────────────────────────────────────┤\n","│ val_ann           │ '/root/ML/dataset_spoon/annotations/validation_annotations.json' │\n","├───────────────────┼──────────────────────────────────────────────────────────────────┤\n","│ test_ann          │ 'instances_test2017.json'                                        │\n","├───────────────────┼──────────────────────────────────────────────────────────────────┤\n","│ mosaic_prob       │ 1.0                                                              │\n","├───────────────────┼──────────────────────────────────────────────────────────────────┤\n","│ mixup_prob        │ 1.0                                                              │\n","├───────────────────┼──────────────────────────────────────────────────────────────────┤\n","│ hsv_prob          │ 1.0                                                              │\n","├───────────────────┼──────────────────────────────────────────────────────────────────┤\n","│ flip_prob         │ 0.5                                                              │\n","├───────────────────┼──────────────────────────────────────────────────────────────────┤\n","│ degrees           │ 10.0                                                             │\n","├───────────────────┼──────────────────────────────────────────────────────────────────┤\n","│ translate         │ 0.1                                                              │\n","├───────────────────┼──────────────────────────────────────────────────────────────────┤\n","│ mosaic_scale      │ (0.1, 2)                                                         │\n","├───────────────────┼──────────────────────────────────────────────────────────────────┤\n","│ enable_mixup      │ True                                                             │\n","├───────────────────┼──────────────────────────────────────────────────────────────────┤\n","│ mixup_scale       │ (0.5, 1.5)                                                       │\n","├───────────────────┼──────────────────────────────────────────────────────────────────┤\n","│ shear             │ 2.0                                                              │\n","├───────────────────┼──────────────────────────────────────────────────────────────────┤\n","│ warmup_epochs     │ 5                                                                │\n","├───────────────────┼──────────────────────────────────────────────────────────────────┤\n","│ max_epoch         │ 20                                                               │\n","├───────────────────┼──────────────────────────────────────────────────────────────────┤\n","│ warmup_lr         │ 0                                                                │\n","├───────────────────┼──────────────────────────────────────────────────────────────────┤\n","│ min_lr_ratio      │ 0.05                                                             │\n","├───────────────────┼──────────────────────────────────────────────────────────────────┤\n","│ basic_lr_per_img  │ 0.00015625                                                       │\n","├───────────────────┼──────────────────────────────────────────────────────────────────┤\n","│ scheduler         │ 'yoloxwarmcos'                                                   │\n","├───────────────────┼──────────────────────────────────────────────────────────────────┤\n","│ no_aug_epochs     │ 15                                                               │\n","├───────────────────┼──────────────────────────────────────────────────────────────────┤\n","│ ema               │ True                                                             │\n","├───────────────────┼──────────────────────────────────────────────────────────────────┤\n","│ weight_decay      │ 0.0005                                                           │\n","├───────────────────┼──────────────────────────────────────────────────────────────────┤\n","│ momentum          │ 0.9                                                              │\n","├───────────────────┼──────────────────────────────────────────────────────────────────┤\n","│ save_history_ckpt │ True                                                             │\n","├───────────────────┼──────────────────────────────────────────────────────────────────┤\n","│ exp_name          │ 'yolox_s'                                                        │\n","├───────────────────┼──────────────────────────────────────────────────────────────────┤\n","│ test_size         │ (640, 640)                                                       │\n","├───────────────────┼──────────────────────────────────────────────────────────────────┤\n","│ test_conf         │ 0.01                                                             │\n","├───────────────────┼──────────────────────────────────────────────────────────────────┤\n","│ nmsthre           │ 0.65                                                             │\n","╘═══════════════════╧══════════════════════════════════════════════════════════════════╛\u001b[0m\n","\u001b[32m2023-01-13 17:08:15\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m136\u001b[0m - \u001b[1mModel Summary: Params: 8.94M, Gflops: 26.76\u001b[0m\n","\u001b[32m2023-01-13 17:08:15\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m311\u001b[0m - \u001b[1mloading checkpoint for fine tuning\u001b[0m\n","\u001b[32m2023-01-13 17:08:15\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36myolox.utils.checkpoint\u001b[0m:\u001b[36m24\u001b[0m - \u001b[33m\u001b[1mShape of head.cls_preds.0.weight in checkpoint is torch.Size([80, 128, 1, 1]), while shape of head.cls_preds.0.weight in model is torch.Size([2, 128, 1, 1]).\u001b[0m\n","\u001b[32m2023-01-13 17:08:15\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36myolox.utils.checkpoint\u001b[0m:\u001b[36m24\u001b[0m - \u001b[33m\u001b[1mShape of head.cls_preds.0.bias in checkpoint is torch.Size([80]), while shape of head.cls_preds.0.bias in model is torch.Size([2]).\u001b[0m\n","\u001b[32m2023-01-13 17:08:15\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36myolox.utils.checkpoint\u001b[0m:\u001b[36m24\u001b[0m - \u001b[33m\u001b[1mShape of head.cls_preds.1.weight in checkpoint is torch.Size([80, 128, 1, 1]), while shape of head.cls_preds.1.weight in model is torch.Size([2, 128, 1, 1]).\u001b[0m\n","\u001b[32m2023-01-13 17:08:15\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36myolox.utils.checkpoint\u001b[0m:\u001b[36m24\u001b[0m - \u001b[33m\u001b[1mShape of head.cls_preds.1.bias in checkpoint is torch.Size([80]), while shape of head.cls_preds.1.bias in model is torch.Size([2]).\u001b[0m\n","\u001b[32m2023-01-13 17:08:15\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36myolox.utils.checkpoint\u001b[0m:\u001b[36m24\u001b[0m - \u001b[33m\u001b[1mShape of head.cls_preds.2.weight in checkpoint is torch.Size([80, 128, 1, 1]), while shape of head.cls_preds.2.weight in model is torch.Size([2, 128, 1, 1]).\u001b[0m\n","\u001b[32m2023-01-13 17:08:15\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36myolox.utils.checkpoint\u001b[0m:\u001b[36m24\u001b[0m - \u001b[33m\u001b[1mShape of head.cls_preds.2.bias in checkpoint is torch.Size([80]), while shape of head.cls_preds.2.bias in model is torch.Size([2]).\u001b[0m\n","\u001b[32m2023-01-13 17:08:15\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.data.datasets.coco\u001b[0m:\u001b[36m64\u001b[0m - \u001b[1mloading annotations into memory...\u001b[0m\n","\u001b[32m2023-01-13 17:08:15\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.data.datasets.coco\u001b[0m:\u001b[36m64\u001b[0m - \u001b[1mDone (t=0.00s)\u001b[0m\n","\u001b[32m2023-01-13 17:08:15\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpycocotools.coco\u001b[0m:\u001b[36m86\u001b[0m - \u001b[1mcreating index...\u001b[0m\n","\u001b[32m2023-01-13 17:08:15\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpycocotools.coco\u001b[0m:\u001b[36m86\u001b[0m - \u001b[1mindex created!\u001b[0m\n","\u001b[32m2023-01-13 17:08:15\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m155\u001b[0m - \u001b[1minit prefetcher, this might take one minute or less...\u001b[0m\n","\u001b[32m2023-01-13 17:08:25\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.data.datasets.coco\u001b[0m:\u001b[36m64\u001b[0m - \u001b[1mloading annotations into memory...\u001b[0m\n","\u001b[32m2023-01-13 17:08:25\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.data.datasets.coco\u001b[0m:\u001b[36m64\u001b[0m - \u001b[1mDone (t=0.00s)\u001b[0m\n","\u001b[32m2023-01-13 17:08:25\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpycocotools.coco\u001b[0m:\u001b[36m86\u001b[0m - \u001b[1mcreating index...\u001b[0m\n","\u001b[32m2023-01-13 17:08:25\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpycocotools.coco\u001b[0m:\u001b[36m86\u001b[0m - \u001b[1mindex created!\u001b[0m\n","\u001b[32m2023-01-13 17:08:25\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mTraining start...\u001b[0m\n","\u001b[32m2023-01-13 17:08:25\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m192\u001b[0m - \u001b[1m\n","DistributedDataParallel(\n","  (module): YOLOX(\n","    (backbone): YOLOPAFPN(\n","      (backbone): CSPDarknet(\n","        (stem): Focus(\n","          (conv): BaseConv(\n","            (conv): Conv2d(12, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (act): SiLU(inplace=True)\n","          )\n","        )\n","        (dark2): Sequential(\n","          (0): BaseConv(\n","            (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (act): SiLU(inplace=True)\n","          )\n","          (1): CSPLayer(\n","            (conv1): BaseConv(\n","              (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","              (act): SiLU(inplace=True)\n","            )\n","            (conv2): BaseConv(\n","              (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","              (act): SiLU(inplace=True)\n","            )\n","            (conv3): BaseConv(\n","              (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","              (act): SiLU(inplace=True)\n","            )\n","            (m): Sequential(\n","              (0): Bottleneck(\n","                (conv1): BaseConv(\n","                  (conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","                  (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","                  (act): SiLU(inplace=True)\n","                )\n","                (conv2): BaseConv(\n","                  (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","                  (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","                  (act): SiLU(inplace=True)\n","                )\n","              )\n","            )\n","          )\n","        )\n","        (dark3): Sequential(\n","          (0): BaseConv(\n","            (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (act): SiLU(inplace=True)\n","          )\n","          (1): CSPLayer(\n","            (conv1): BaseConv(\n","              (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","              (act): SiLU(inplace=True)\n","            )\n","            (conv2): BaseConv(\n","              (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","              (act): SiLU(inplace=True)\n","            )\n","            (conv3): BaseConv(\n","              (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","              (act): SiLU(inplace=True)\n","            )\n","            (m): Sequential(\n","              (0): Bottleneck(\n","                (conv1): BaseConv(\n","                  (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","                  (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","                  (act): SiLU(inplace=True)\n","                )\n","                (conv2): BaseConv(\n","                  (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","                  (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","                  (act): SiLU(inplace=True)\n","                )\n","              )\n","              (1): Bottleneck(\n","                (conv1): BaseConv(\n","                  (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","                  (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","                  (act): SiLU(inplace=True)\n","                )\n","                (conv2): BaseConv(\n","                  (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","                  (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","                  (act): SiLU(inplace=True)\n","                )\n","              )\n","              (2): Bottleneck(\n","                (conv1): BaseConv(\n","                  (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","                  (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","                  (act): SiLU(inplace=True)\n","                )\n","                (conv2): BaseConv(\n","                  (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","                  (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","                  (act): SiLU(inplace=True)\n","                )\n","              )\n","            )\n","          )\n","        )\n","        (dark4): Sequential(\n","          (0): BaseConv(\n","            (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (act): SiLU(inplace=True)\n","          )\n","          (1): CSPLayer(\n","            (conv1): BaseConv(\n","              (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","              (act): SiLU(inplace=True)\n","            )\n","            (conv2): BaseConv(\n","              (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","              (act): SiLU(inplace=True)\n","            )\n","            (conv3): BaseConv(\n","              (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","              (act): SiLU(inplace=True)\n","            )\n","            (m): Sequential(\n","              (0): Bottleneck(\n","                (conv1): BaseConv(\n","                  (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","                  (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","                  (act): SiLU(inplace=True)\n","                )\n","                (conv2): BaseConv(\n","                  (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","                  (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","                  (act): SiLU(inplace=True)\n","                )\n","              )\n","              (1): Bottleneck(\n","                (conv1): BaseConv(\n","                  (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","                  (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","                  (act): SiLU(inplace=True)\n","                )\n","                (conv2): BaseConv(\n","                  (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","                  (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","                  (act): SiLU(inplace=True)\n","                )\n","              )\n","              (2): Bottleneck(\n","                (conv1): BaseConv(\n","                  (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","                  (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","                  (act): SiLU(inplace=True)\n","                )\n","                (conv2): BaseConv(\n","                  (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","                  (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","                  (act): SiLU(inplace=True)\n","                )\n","              )\n","            )\n","          )\n","        )\n","        (dark5): Sequential(\n","          (0): BaseConv(\n","            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (act): SiLU(inplace=True)\n","          )\n","          (1): SPPBottleneck(\n","            (conv1): BaseConv(\n","              (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","              (act): SiLU(inplace=True)\n","            )\n","            (m): ModuleList(\n","              (0): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)\n","              (1): MaxPool2d(kernel_size=9, stride=1, padding=4, dilation=1, ceil_mode=False)\n","              (2): MaxPool2d(kernel_size=13, stride=1, padding=6, dilation=1, ceil_mode=False)\n","            )\n","            (conv2): BaseConv(\n","              (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","              (act): SiLU(inplace=True)\n","            )\n","          )\n","          (2): CSPLayer(\n","            (conv1): BaseConv(\n","              (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","              (act): SiLU(inplace=True)\n","            )\n","            (conv2): BaseConv(\n","              (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","              (act): SiLU(inplace=True)\n","            )\n","            (conv3): BaseConv(\n","              (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","              (act): SiLU(inplace=True)\n","            )\n","            (m): Sequential(\n","              (0): Bottleneck(\n","                (conv1): BaseConv(\n","                  (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","                  (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","                  (act): SiLU(inplace=True)\n","                )\n","                (conv2): BaseConv(\n","                  (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","                  (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","                  (act): SiLU(inplace=True)\n","                )\n","              )\n","            )\n","          )\n","        )\n","      )\n","      (upsample): Upsample(scale_factor=2.0, mode=nearest)\n","      (lateral_conv0): BaseConv(\n","        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        (act): SiLU(inplace=True)\n","      )\n","      (C3_p4): CSPLayer(\n","        (conv1): BaseConv(\n","          (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          (act): SiLU(inplace=True)\n","        )\n","        (conv2): BaseConv(\n","          (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          (act): SiLU(inplace=True)\n","        )\n","        (conv3): BaseConv(\n","          (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          (act): SiLU(inplace=True)\n","        )\n","        (m): Sequential(\n","          (0): Bottleneck(\n","            (conv1): BaseConv(\n","              (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","              (act): SiLU(inplace=True)\n","            )\n","            (conv2): BaseConv(\n","              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","              (act): SiLU(inplace=True)\n","            )\n","          )\n","        )\n","      )\n","      (reduce_conv1): BaseConv(\n","        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        (act): SiLU(inplace=True)\n","      )\n","      (C3_p3): CSPLayer(\n","        (conv1): BaseConv(\n","          (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          (act): SiLU(inplace=True)\n","        )\n","        (conv2): BaseConv(\n","          (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          (act): SiLU(inplace=True)\n","        )\n","        (conv3): BaseConv(\n","          (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          (act): SiLU(inplace=True)\n","        )\n","        (m): Sequential(\n","          (0): Bottleneck(\n","            (conv1): BaseConv(\n","              (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","              (act): SiLU(inplace=True)\n","            )\n","            (conv2): BaseConv(\n","              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","              (act): SiLU(inplace=True)\n","            )\n","          )\n","        )\n","      )\n","      (bu_conv2): BaseConv(\n","        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        (act): SiLU(inplace=True)\n","      )\n","      (C3_n3): CSPLayer(\n","        (conv1): BaseConv(\n","          (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          (act): SiLU(inplace=True)\n","        )\n","        (conv2): BaseConv(\n","          (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          (act): SiLU(inplace=True)\n","        )\n","        (conv3): BaseConv(\n","          (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          (act): SiLU(inplace=True)\n","        )\n","        (m): Sequential(\n","          (0): Bottleneck(\n","            (conv1): BaseConv(\n","              (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","              (act): SiLU(inplace=True)\n","            )\n","            (conv2): BaseConv(\n","              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","              (act): SiLU(inplace=True)\n","            )\n","          )\n","        )\n","      )\n","      (bu_conv1): BaseConv(\n","        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        (act): SiLU(inplace=True)\n","      )\n","      (C3_n4): CSPLayer(\n","        (conv1): BaseConv(\n","          (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          (act): SiLU(inplace=True)\n","        )\n","        (conv2): BaseConv(\n","          (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          (act): SiLU(inplace=True)\n","        )\n","        (conv3): BaseConv(\n","          (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          (act): SiLU(inplace=True)\n","        )\n","        (m): Sequential(\n","          (0): Bottleneck(\n","            (conv1): BaseConv(\n","              (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","              (act): SiLU(inplace=True)\n","            )\n","            (conv2): BaseConv(\n","              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","              (act): SiLU(inplace=True)\n","            )\n","          )\n","        )\n","      )\n","    )\n","    (head): YOLOXHead(\n","      (cls_convs): ModuleList(\n","        (0): Sequential(\n","          (0): BaseConv(\n","            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (act): SiLU(inplace=True)\n","          )\n","          (1): BaseConv(\n","            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (act): SiLU(inplace=True)\n","          )\n","        )\n","        (1): Sequential(\n","          (0): BaseConv(\n","            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (act): SiLU(inplace=True)\n","          )\n","          (1): BaseConv(\n","            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (act): SiLU(inplace=True)\n","          )\n","        )\n","        (2): Sequential(\n","          (0): BaseConv(\n","            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (act): SiLU(inplace=True)\n","          )\n","          (1): BaseConv(\n","            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (act): SiLU(inplace=True)\n","          )\n","        )\n","      )\n","      (reg_convs): ModuleList(\n","        (0): Sequential(\n","          (0): BaseConv(\n","            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (act): SiLU(inplace=True)\n","          )\n","          (1): BaseConv(\n","            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (act): SiLU(inplace=True)\n","          )\n","        )\n","        (1): Sequential(\n","          (0): BaseConv(\n","            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (act): SiLU(inplace=True)\n","          )\n","          (1): BaseConv(\n","            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (act): SiLU(inplace=True)\n","          )\n","        )\n","        (2): Sequential(\n","          (0): BaseConv(\n","            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (act): SiLU(inplace=True)\n","          )\n","          (1): BaseConv(\n","            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (act): SiLU(inplace=True)\n","          )\n","        )\n","      )\n","      (cls_preds): ModuleList(\n","        (0): Conv2d(128, 2, kernel_size=(1, 1), stride=(1, 1))\n","        (1): Conv2d(128, 2, kernel_size=(1, 1), stride=(1, 1))\n","        (2): Conv2d(128, 2, kernel_size=(1, 1), stride=(1, 1))\n","      )\n","      (reg_preds): ModuleList(\n","        (0): Conv2d(128, 4, kernel_size=(1, 1), stride=(1, 1))\n","        (1): Conv2d(128, 4, kernel_size=(1, 1), stride=(1, 1))\n","        (2): Conv2d(128, 4, kernel_size=(1, 1), stride=(1, 1))\n","      )\n","      (obj_preds): ModuleList(\n","        (0): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))\n","        (1): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))\n","        (2): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))\n","      )\n","      (stems): ModuleList(\n","        (0): BaseConv(\n","          (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          (act): SiLU(inplace=True)\n","        )\n","        (1): BaseConv(\n","          (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          (act): SiLU(inplace=True)\n","        )\n","        (2): BaseConv(\n","          (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          (act): SiLU(inplace=True)\n","        )\n","      )\n","      (l1_loss): L1Loss()\n","      (bcewithlog_loss): BCEWithLogitsLoss()\n","      (iou_loss): IOUloss()\n","    )\n","  )\n",")\u001b[0m\n","\u001b[32m2023-01-13 17:08:25\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m203\u001b[0m - \u001b[1m---> start train epoch1\u001b[0m\n","\u001b[32m2023-01-13 17:08:28\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m195\u001b[0m - \u001b[1mTraining of experiment is done and the best AP is 0.00\u001b[0m\n","\u001b[32m2023-01-13 17:08:28\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36myolox.core.launch\u001b[0m:\u001b[36m147\u001b[0m - \u001b[31m\u001b[1mAn error has been caught in function '_distributed_worker', process 'SpawnProcess-1' (62262), thread 'MainThread' (140057240573760):\u001b[0m\n","\u001b[33m\u001b[1mTraceback (most recent call last):\u001b[0m\n","\n","  File \"<string>\", line 1, in <module>\n","  File \"/usr/lib/python3.8/multiprocessing/spawn.py\", line 116, in spawn_main\n","    exitcode = _main(fd, parent_sentinel)\n","               │     │   └ 5\n","               │     └ 8\n","               └ <function _main at 0x7f619ddc5ee0>\n","  File \"/usr/lib/python3.8/multiprocessing/spawn.py\", line 129, in _main\n","    return self._bootstrap(parent_sentinel)\n","           │    │          └ 5\n","           │    └ <function BaseProcess._bootstrap at 0x7f619dec79d0>\n","           └ <SpawnProcess name='SpawnProcess-1' parent=62237 started>\n","  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n","    self.run()\n","    │    └ <function BaseProcess.run at 0x7f619dec7040>\n","    └ <SpawnProcess name='SpawnProcess-1' parent=62237 started>\n","  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n","    self._target(*self._args, **self._kwargs)\n","    │    │        │    │        │    └ {}\n","    │    │        │    │        └ <SpawnProcess name='SpawnProcess-1' parent=62237 started>\n","    │    │        │    └ (<function _distributed_worker at 0x7f610e094040>, 0, (<function main at 0x7f61003b7700>, 2, 2, 0, 'nccl', 'tcp://127.0.0.1:5...\n","    │    │        └ <SpawnProcess name='SpawnProcess-1' parent=62237 started>\n","    │    └ <function _wrap at 0x7f610ed758b0>\n","    └ <SpawnProcess name='SpawnProcess-1' parent=62237 started>\n","\n","  File \"\u001b[32m/usr/local/lib/python3.8/dist-packages/torch/multiprocessing/\u001b[0m\u001b[32m\u001b[1mspawn.py\u001b[0m\", line \u001b[33m69\u001b[0m, in \u001b[35m_wrap\u001b[0m\n","    \u001b[1mfn\u001b[0m\u001b[1m(\u001b[0m\u001b[1mi\u001b[0m\u001b[1m,\u001b[0m \u001b[35m\u001b[1m*\u001b[0m\u001b[1margs\u001b[0m\u001b[1m)\u001b[0m\n","    \u001b[36m│  │   └ \u001b[0m\u001b[36m\u001b[1m(<function main at 0x7f61003b7700>, 2, 2, 0, 'nccl', 'tcp://127.0.0.1:50677', (╒═══════════════════╤═════════════════════════...\u001b[0m\n","    \u001b[36m│  └ \u001b[0m\u001b[36m\u001b[1m0\u001b[0m\n","    \u001b[36m└ \u001b[0m\u001b[36m\u001b[1m<function _distributed_worker at 0x7f610e094040>\u001b[0m\n","\n","> File \"\u001b[32m/root/YOLOX/yolox/core/\u001b[0m\u001b[32m\u001b[1mlaunch.py\u001b[0m\", line \u001b[33m147\u001b[0m, in \u001b[35m_distributed_worker\u001b[0m\n","    \u001b[1mmain_func\u001b[0m\u001b[1m(\u001b[0m\u001b[35m\u001b[1m*\u001b[0m\u001b[1margs\u001b[0m\u001b[1m)\u001b[0m\n","    \u001b[36m│          └ \u001b[0m\u001b[36m\u001b[1m(╒═══════════════════╤═══════════════════════════════════════════════════════════════════════════════════════════════════════...\u001b[0m\n","    \u001b[36m└ \u001b[0m\u001b[36m\u001b[1m<function main at 0x7f61003b7700>\u001b[0m\n","\n","  File \"\u001b[32m/root/YOLOX/tools/\u001b[0m\u001b[32m\u001b[1mtrain.py\u001b[0m\", line \u001b[33m118\u001b[0m, in \u001b[35mmain\u001b[0m\n","    \u001b[1mtrainer\u001b[0m\u001b[35m\u001b[1m.\u001b[0m\u001b[1mtrain\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n","    \u001b[36m│       └ \u001b[0m\u001b[36m\u001b[1m<function Trainer.train at 0x7f60ffa21430>\u001b[0m\n","    \u001b[36m└ \u001b[0m\u001b[36m\u001b[1m<yolox.core.trainer.Trainer object at 0x7f60ff9b7df0>\u001b[0m\n","\n","  File \"\u001b[32m/root/YOLOX/yolox/core/\u001b[0m\u001b[32m\u001b[1mtrainer.py\u001b[0m\", line \u001b[33m76\u001b[0m, in \u001b[35mtrain\u001b[0m\n","    \u001b[1mself\u001b[0m\u001b[35m\u001b[1m.\u001b[0m\u001b[1mtrain_in_epoch\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n","    \u001b[36m│    └ \u001b[0m\u001b[36m\u001b[1m<function Trainer.train_in_epoch at 0x7f60ffa21af0>\u001b[0m\n","    \u001b[36m└ \u001b[0m\u001b[36m\u001b[1m<yolox.core.trainer.Trainer object at 0x7f60ff9b7df0>\u001b[0m\n","\n","  File \"\u001b[32m/root/YOLOX/yolox/core/\u001b[0m\u001b[32m\u001b[1mtrainer.py\u001b[0m\", line \u001b[33m85\u001b[0m, in \u001b[35mtrain_in_epoch\u001b[0m\n","    \u001b[1mself\u001b[0m\u001b[35m\u001b[1m.\u001b[0m\u001b[1mtrain_in_iter\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n","    \u001b[36m│    └ \u001b[0m\u001b[36m\u001b[1m<function Trainer.train_in_iter at 0x7f60ffa21b80>\u001b[0m\n","    \u001b[36m└ \u001b[0m\u001b[36m\u001b[1m<yolox.core.trainer.Trainer object at 0x7f60ff9b7df0>\u001b[0m\n","\n","  File \"\u001b[32m/root/YOLOX/yolox/core/\u001b[0m\u001b[32m\u001b[1mtrainer.py\u001b[0m\", line \u001b[33m91\u001b[0m, in \u001b[35mtrain_in_iter\u001b[0m\n","    \u001b[1mself\u001b[0m\u001b[35m\u001b[1m.\u001b[0m\u001b[1mtrain_one_iter\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n","    \u001b[36m│    └ \u001b[0m\u001b[36m\u001b[1m<function Trainer.train_one_iter at 0x7f60ffa21c10>\u001b[0m\n","    \u001b[36m└ \u001b[0m\u001b[36m\u001b[1m<yolox.core.trainer.Trainer object at 0x7f60ff9b7df0>\u001b[0m\n","\n","  File \"\u001b[32m/root/YOLOX/yolox/core/\u001b[0m\u001b[32m\u001b[1mtrainer.py\u001b[0m\", line \u001b[33m105\u001b[0m, in \u001b[35mtrain_one_iter\u001b[0m\n","    \u001b[1moutputs\u001b[0m \u001b[35m\u001b[1m=\u001b[0m \u001b[1mself\u001b[0m\u001b[35m\u001b[1m.\u001b[0m\u001b[1mmodel\u001b[0m\u001b[1m(\u001b[0m\u001b[1minps\u001b[0m\u001b[1m,\u001b[0m \u001b[1mtargets\u001b[0m\u001b[1m)\u001b[0m\n","    \u001b[36m          │    │     │     └ \u001b[0m\u001b[36m\u001b[1mtensor([[[  1.0000, 286.7500, 267.0000,  36.4375,  40.7500],\u001b[0m\n","    \u001b[36m          │    │     │       \u001b[0m\u001b[36m\u001b[1m         [  0.0000, 378.5000, 559.0000,  23.1719,  41.2500],\u001b[0m\n","    \u001b[36m          │    │     │       \u001b[0m\u001b[36m\u001b[1m   ...\u001b[0m\n","    \u001b[36m          │    │     └ \u001b[0m\u001b[36m\u001b[1mtensor([[[[ 56.,  56.,  56.,  ..., 138., 138., 138.],\u001b[0m\n","    \u001b[36m          │    │       \u001b[0m\u001b[36m\u001b[1m          [ 56.,  56.,  56.,  ..., 141., 141., 141.],\u001b[0m\n","    \u001b[36m          │    │       \u001b[0m\u001b[36m\u001b[1m          [ 56., ...\u001b[0m\n","    \u001b[36m          │    └ \u001b[0m\u001b[36m\u001b[1mDistributedDataParallel(\u001b[0m\n","    \u001b[36m          │      \u001b[0m\u001b[36m\u001b[1m  (module): YOLOX(\u001b[0m\n","    \u001b[36m          │      \u001b[0m\u001b[36m\u001b[1m    (backbone): YOLOPAFPN(\u001b[0m\n","    \u001b[36m          │      \u001b[0m\u001b[36m\u001b[1m      (backbone): CSPDarknet(\u001b[0m\n","    \u001b[36m          │      \u001b[0m\u001b[36m\u001b[1m        (stem): Focus(\u001b[0m\n","    \u001b[36m          │      \u001b[0m\u001b[36m\u001b[1m ...\u001b[0m\n","    \u001b[36m          └ \u001b[0m\u001b[36m\u001b[1m<yolox.core.trainer.Trainer object at 0x7f60ff9b7df0>\u001b[0m\n","\n","  File \"\u001b[32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/\u001b[0m\u001b[32m\u001b[1mmodule.py\u001b[0m\", line \u001b[33m1190\u001b[0m, in \u001b[35m_call_impl\u001b[0m\n","    \u001b[35m\u001b[1mreturn\u001b[0m \u001b[1mforward_call\u001b[0m\u001b[1m(\u001b[0m\u001b[35m\u001b[1m*\u001b[0m\u001b[1minput\u001b[0m\u001b[1m,\u001b[0m \u001b[35m\u001b[1m**\u001b[0m\u001b[1mkwargs\u001b[0m\u001b[1m)\u001b[0m\n","    \u001b[36m       │             │        └ \u001b[0m\u001b[36m\u001b[1m{}\u001b[0m\n","    \u001b[36m       │             └ \u001b[0m\u001b[36m\u001b[1m(tensor([[[[ 56.,  56.,  56.,  ..., 138., 138., 138.],\u001b[0m\n","    \u001b[36m       │               \u001b[0m\u001b[36m\u001b[1m          [ 56.,  56.,  56.,  ..., 141., 141., 141.],\u001b[0m\n","    \u001b[36m       │               \u001b[0m\u001b[36m\u001b[1m          [ 56.,...\u001b[0m\n","    \u001b[36m       └ \u001b[0m\u001b[36m\u001b[1m<bound method DistributedDataParallel.forward of DistributedDataParallel(\u001b[0m\n","    \u001b[36m         \u001b[0m\u001b[36m\u001b[1m  (module): YOLOX(\u001b[0m\n","    \u001b[36m         \u001b[0m\u001b[36m\u001b[1m    (backbone): YOLOPAFPN(\u001b[0m\n","    \u001b[36m         \u001b[0m\u001b[36m\u001b[1m     ...\u001b[0m\n","\n","  File \"\u001b[32m/usr/local/lib/python3.8/dist-packages/torch/nn/parallel/\u001b[0m\u001b[32m\u001b[1mdistributed.py\u001b[0m\", line \u001b[33m1040\u001b[0m, in \u001b[35mforward\u001b[0m\n","    \u001b[1moutput\u001b[0m \u001b[35m\u001b[1m=\u001b[0m \u001b[1mself\u001b[0m\u001b[35m\u001b[1m.\u001b[0m\u001b[1m_run_ddp_forward\u001b[0m\u001b[1m(\u001b[0m\u001b[35m\u001b[1m*\u001b[0m\u001b[1minputs\u001b[0m\u001b[1m,\u001b[0m \u001b[35m\u001b[1m**\u001b[0m\u001b[1mkwargs\u001b[0m\u001b[1m)\u001b[0m\n","    \u001b[36m         │    │                 │         └ \u001b[0m\u001b[36m\u001b[1m{}\u001b[0m\n","    \u001b[36m         │    │                 └ \u001b[0m\u001b[36m\u001b[1m(tensor([[[[ 56.,  56.,  56.,  ..., 138., 138., 138.],\u001b[0m\n","    \u001b[36m         │    │                   \u001b[0m\u001b[36m\u001b[1m          [ 56.,  56.,  56.,  ..., 141., 141., 141.],\u001b[0m\n","    \u001b[36m         │    │                   \u001b[0m\u001b[36m\u001b[1m          [ 56.,...\u001b[0m\n","    \u001b[36m         │    └ \u001b[0m\u001b[36m\u001b[1m<function DistributedDataParallel._run_ddp_forward at 0x7f610edce5e0>\u001b[0m\n","    \u001b[36m         └ \u001b[0m\u001b[36m\u001b[1mDistributedDataParallel(\u001b[0m\n","    \u001b[36m           \u001b[0m\u001b[36m\u001b[1m  (module): YOLOX(\u001b[0m\n","    \u001b[36m           \u001b[0m\u001b[36m\u001b[1m    (backbone): YOLOPAFPN(\u001b[0m\n","    \u001b[36m           \u001b[0m\u001b[36m\u001b[1m      (backbone): CSPDarknet(\u001b[0m\n","    \u001b[36m           \u001b[0m\u001b[36m\u001b[1m        (stem): Focus(\u001b[0m\n","    \u001b[36m           \u001b[0m\u001b[36m\u001b[1m ...\u001b[0m\n","\n","  File \"\u001b[32m/usr/local/lib/python3.8/dist-packages/torch/nn/parallel/\u001b[0m\u001b[32m\u001b[1mdistributed.py\u001b[0m\", line \u001b[33m1000\u001b[0m, in \u001b[35m_run_ddp_forward\u001b[0m\n","    \u001b[35m\u001b[1mreturn\u001b[0m \u001b[1mmodule_to_run\u001b[0m\u001b[1m(\u001b[0m\u001b[35m\u001b[1m*\u001b[0m\u001b[1minputs\u001b[0m\u001b[1m[\u001b[0m\u001b[34m\u001b[1m0\u001b[0m\u001b[1m]\u001b[0m\u001b[1m,\u001b[0m \u001b[35m\u001b[1m**\u001b[0m\u001b[1mkwargs\u001b[0m\u001b[1m[\u001b[0m\u001b[34m\u001b[1m0\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n","    \u001b[36m       │              │            └ \u001b[0m\u001b[36m\u001b[1m({},)\u001b[0m\n","    \u001b[36m       │              └ \u001b[0m\u001b[36m\u001b[1m((tensor([[[[ 56.,  56.,  56.,  ..., 138., 138., 138.],\u001b[0m\n","    \u001b[36m       │                \u001b[0m\u001b[36m\u001b[1m          [ 56.,  56.,  56.,  ..., 141., 141., 141.],\u001b[0m\n","    \u001b[36m       │                \u001b[0m\u001b[36m\u001b[1m          [ 56....\u001b[0m\n","    \u001b[36m       └ \u001b[0m\u001b[36m\u001b[1mYOLOX(\u001b[0m\n","    \u001b[36m         \u001b[0m\u001b[36m\u001b[1m  (backbone): YOLOPAFPN(\u001b[0m\n","    \u001b[36m         \u001b[0m\u001b[36m\u001b[1m    (backbone): CSPDarknet(\u001b[0m\n","    \u001b[36m         \u001b[0m\u001b[36m\u001b[1m      (stem): Focus(\u001b[0m\n","    \u001b[36m         \u001b[0m\u001b[36m\u001b[1m        (conv): BaseConv(\u001b[0m\n","    \u001b[36m         \u001b[0m\u001b[36m\u001b[1m          (conv): ...\u001b[0m\n","\n","  File \"\u001b[32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/\u001b[0m\u001b[32m\u001b[1mmodule.py\u001b[0m\", line \u001b[33m1190\u001b[0m, in \u001b[35m_call_impl\u001b[0m\n","    \u001b[35m\u001b[1mreturn\u001b[0m \u001b[1mforward_call\u001b[0m\u001b[1m(\u001b[0m\u001b[35m\u001b[1m*\u001b[0m\u001b[1minput\u001b[0m\u001b[1m,\u001b[0m \u001b[35m\u001b[1m**\u001b[0m\u001b[1mkwargs\u001b[0m\u001b[1m)\u001b[0m\n","    \u001b[36m       │             │        └ \u001b[0m\u001b[36m\u001b[1m{}\u001b[0m\n","    \u001b[36m       │             └ \u001b[0m\u001b[36m\u001b[1m(tensor([[[[ 56.,  56.,  56.,  ..., 138., 138., 138.],\u001b[0m\n","    \u001b[36m       │               \u001b[0m\u001b[36m\u001b[1m          [ 56.,  56.,  56.,  ..., 141., 141., 141.],\u001b[0m\n","    \u001b[36m       │               \u001b[0m\u001b[36m\u001b[1m          [ 56.,...\u001b[0m\n","    \u001b[36m       └ \u001b[0m\u001b[36m\u001b[1m<bound method YOLOX.forward of YOLOX(\u001b[0m\n","    \u001b[36m         \u001b[0m\u001b[36m\u001b[1m  (backbone): YOLOPAFPN(\u001b[0m\n","    \u001b[36m         \u001b[0m\u001b[36m\u001b[1m    (backbone): CSPDarknet(\u001b[0m\n","    \u001b[36m         \u001b[0m\u001b[36m\u001b[1m      (stem): Focus(\u001b[0m\n","    \u001b[36m         \u001b[0m\u001b[36m\u001b[1m        (conv...\u001b[0m\n","\n","  File \"\u001b[32m/root/YOLOX/yolox/models/\u001b[0m\u001b[32m\u001b[1myolox.py\u001b[0m\", line \u001b[33m30\u001b[0m, in \u001b[35mforward\u001b[0m\n","    \u001b[1mfpn_outs\u001b[0m \u001b[35m\u001b[1m=\u001b[0m \u001b[1mself\u001b[0m\u001b[35m\u001b[1m.\u001b[0m\u001b[1mbackbone\u001b[0m\u001b[1m(\u001b[0m\u001b[1mx\u001b[0m\u001b[1m)\u001b[0m\n","    \u001b[36m           │             └ \u001b[0m\u001b[36m\u001b[1mtensor([[[[ 56.,  56.,  56.,  ..., 138., 138., 138.],\u001b[0m\n","    \u001b[36m           │               \u001b[0m\u001b[36m\u001b[1m          [ 56.,  56.,  56.,  ..., 141., 141., 141.],\u001b[0m\n","    \u001b[36m           │               \u001b[0m\u001b[36m\u001b[1m          [ 56., ...\u001b[0m\n","    \u001b[36m           └ \u001b[0m\u001b[36m\u001b[1mYOLOX(\u001b[0m\n","    \u001b[36m             \u001b[0m\u001b[36m\u001b[1m  (backbone): YOLOPAFPN(\u001b[0m\n","    \u001b[36m             \u001b[0m\u001b[36m\u001b[1m    (backbone): CSPDarknet(\u001b[0m\n","    \u001b[36m             \u001b[0m\u001b[36m\u001b[1m      (stem): Focus(\u001b[0m\n","    \u001b[36m             \u001b[0m\u001b[36m\u001b[1m        (conv): BaseConv(\u001b[0m\n","    \u001b[36m             \u001b[0m\u001b[36m\u001b[1m          (conv): ...\u001b[0m\n","\n","  File \"\u001b[32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/\u001b[0m\u001b[32m\u001b[1mmodule.py\u001b[0m\", line \u001b[33m1190\u001b[0m, in \u001b[35m_call_impl\u001b[0m\n","    \u001b[35m\u001b[1mreturn\u001b[0m \u001b[1mforward_call\u001b[0m\u001b[1m(\u001b[0m\u001b[35m\u001b[1m*\u001b[0m\u001b[1minput\u001b[0m\u001b[1m,\u001b[0m \u001b[35m\u001b[1m**\u001b[0m\u001b[1mkwargs\u001b[0m\u001b[1m)\u001b[0m\n","    \u001b[36m       │             │        └ \u001b[0m\u001b[36m\u001b[1m{}\u001b[0m\n","    \u001b[36m       │             └ \u001b[0m\u001b[36m\u001b[1m(tensor([[[[ 56.,  56.,  56.,  ..., 138., 138., 138.],\u001b[0m\n","    \u001b[36m       │               \u001b[0m\u001b[36m\u001b[1m          [ 56.,  56.,  56.,  ..., 141., 141., 141.],\u001b[0m\n","    \u001b[36m       │               \u001b[0m\u001b[36m\u001b[1m          [ 56.,...\u001b[0m\n","    \u001b[36m       └ \u001b[0m\u001b[36m\u001b[1m<bound method YOLOPAFPN.forward of YOLOPAFPN(\u001b[0m\n","    \u001b[36m         \u001b[0m\u001b[36m\u001b[1m  (backbone): CSPDarknet(\u001b[0m\n","    \u001b[36m         \u001b[0m\u001b[36m\u001b[1m    (stem): Focus(\u001b[0m\n","    \u001b[36m         \u001b[0m\u001b[36m\u001b[1m      (conv): BaseConv(\u001b[0m\n","    \u001b[36m         \u001b[0m\u001b[36m\u001b[1m        (c...\u001b[0m\n","\n","  File \"\u001b[32m/root/YOLOX/yolox/models/\u001b[0m\u001b[32m\u001b[1myolo_pafpn.py\u001b[0m\", line \u001b[33m93\u001b[0m, in \u001b[35mforward\u001b[0m\n","    \u001b[1mout_features\u001b[0m \u001b[35m\u001b[1m=\u001b[0m \u001b[1mself\u001b[0m\u001b[35m\u001b[1m.\u001b[0m\u001b[1mbackbone\u001b[0m\u001b[1m(\u001b[0m\u001b[1minput\u001b[0m\u001b[1m)\u001b[0m\n","    \u001b[36m               │             └ \u001b[0m\u001b[36m\u001b[1mtensor([[[[ 56.,  56.,  56.,  ..., 138., 138., 138.],\u001b[0m\n","    \u001b[36m               │               \u001b[0m\u001b[36m\u001b[1m          [ 56.,  56.,  56.,  ..., 141., 141., 141.],\u001b[0m\n","    \u001b[36m               │               \u001b[0m\u001b[36m\u001b[1m          [ 56., ...\u001b[0m\n","    \u001b[36m               └ \u001b[0m\u001b[36m\u001b[1mYOLOPAFPN(\u001b[0m\n","    \u001b[36m                 \u001b[0m\u001b[36m\u001b[1m  (backbone): CSPDarknet(\u001b[0m\n","    \u001b[36m                 \u001b[0m\u001b[36m\u001b[1m    (stem): Focus(\u001b[0m\n","    \u001b[36m                 \u001b[0m\u001b[36m\u001b[1m      (conv): BaseConv(\u001b[0m\n","    \u001b[36m                 \u001b[0m\u001b[36m\u001b[1m        (conv): Conv2d(12, 32, kernel_size=(3...\u001b[0m\n","\n","  File \"\u001b[32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/\u001b[0m\u001b[32m\u001b[1mmodule.py\u001b[0m\", line \u001b[33m1190\u001b[0m, in \u001b[35m_call_impl\u001b[0m\n","    \u001b[35m\u001b[1mreturn\u001b[0m \u001b[1mforward_call\u001b[0m\u001b[1m(\u001b[0m\u001b[35m\u001b[1m*\u001b[0m\u001b[1minput\u001b[0m\u001b[1m,\u001b[0m \u001b[35m\u001b[1m**\u001b[0m\u001b[1mkwargs\u001b[0m\u001b[1m)\u001b[0m\n","    \u001b[36m       │             │        └ \u001b[0m\u001b[36m\u001b[1m{}\u001b[0m\n","    \u001b[36m       │             └ \u001b[0m\u001b[36m\u001b[1m(tensor([[[[ 56.,  56.,  56.,  ..., 138., 138., 138.],\u001b[0m\n","    \u001b[36m       │               \u001b[0m\u001b[36m\u001b[1m          [ 56.,  56.,  56.,  ..., 141., 141., 141.],\u001b[0m\n","    \u001b[36m       │               \u001b[0m\u001b[36m\u001b[1m          [ 56.,...\u001b[0m\n","    \u001b[36m       └ \u001b[0m\u001b[36m\u001b[1m<bound method CSPDarknet.forward of CSPDarknet(\u001b[0m\n","    \u001b[36m         \u001b[0m\u001b[36m\u001b[1m  (stem): Focus(\u001b[0m\n","    \u001b[36m         \u001b[0m\u001b[36m\u001b[1m    (conv): BaseConv(\u001b[0m\n","    \u001b[36m         \u001b[0m\u001b[36m\u001b[1m      (conv): Conv2d(12, 32, kernel_si...\u001b[0m\n","\n","  File \"\u001b[32m/root/YOLOX/yolox/models/\u001b[0m\u001b[32m\u001b[1mdarknet.py\u001b[0m\", line \u001b[33m169\u001b[0m, in \u001b[35mforward\u001b[0m\n","    \u001b[1mx\u001b[0m \u001b[35m\u001b[1m=\u001b[0m \u001b[1mself\u001b[0m\u001b[35m\u001b[1m.\u001b[0m\u001b[1mstem\u001b[0m\u001b[1m(\u001b[0m\u001b[1mx\u001b[0m\u001b[1m)\u001b[0m\n","    \u001b[36m    │         └ \u001b[0m\u001b[36m\u001b[1mtensor([[[[ 56.,  56.,  56.,  ..., 138., 138., 138.],\u001b[0m\n","    \u001b[36m    │           \u001b[0m\u001b[36m\u001b[1m          [ 56.,  56.,  56.,  ..., 141., 141., 141.],\u001b[0m\n","    \u001b[36m    │           \u001b[0m\u001b[36m\u001b[1m          [ 56., ...\u001b[0m\n","    \u001b[36m    └ \u001b[0m\u001b[36m\u001b[1mCSPDarknet(\u001b[0m\n","    \u001b[36m      \u001b[0m\u001b[36m\u001b[1m  (stem): Focus(\u001b[0m\n","    \u001b[36m      \u001b[0m\u001b[36m\u001b[1m    (conv): BaseConv(\u001b[0m\n","    \u001b[36m      \u001b[0m\u001b[36m\u001b[1m      (conv): Conv2d(12, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1...\u001b[0m\n","\n","  File \"\u001b[32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/\u001b[0m\u001b[32m\u001b[1mmodule.py\u001b[0m\", line \u001b[33m1190\u001b[0m, in \u001b[35m_call_impl\u001b[0m\n","    \u001b[35m\u001b[1mreturn\u001b[0m \u001b[1mforward_call\u001b[0m\u001b[1m(\u001b[0m\u001b[35m\u001b[1m*\u001b[0m\u001b[1minput\u001b[0m\u001b[1m,\u001b[0m \u001b[35m\u001b[1m**\u001b[0m\u001b[1mkwargs\u001b[0m\u001b[1m)\u001b[0m\n","    \u001b[36m       │             │        └ \u001b[0m\u001b[36m\u001b[1m{}\u001b[0m\n","    \u001b[36m       │             └ \u001b[0m\u001b[36m\u001b[1m(tensor([[[[ 56.,  56.,  56.,  ..., 138., 138., 138.],\u001b[0m\n","    \u001b[36m       │               \u001b[0m\u001b[36m\u001b[1m          [ 56.,  56.,  56.,  ..., 141., 141., 141.],\u001b[0m\n","    \u001b[36m       │               \u001b[0m\u001b[36m\u001b[1m          [ 56.,...\u001b[0m\n","    \u001b[36m       └ \u001b[0m\u001b[36m\u001b[1m<bound method Focus.forward of Focus(\u001b[0m\n","    \u001b[36m         \u001b[0m\u001b[36m\u001b[1m  (conv): BaseConv(\u001b[0m\n","    \u001b[36m         \u001b[0m\u001b[36m\u001b[1m    (conv): Conv2d(12, 32, kernel_size=(3, 3), stride=(1, 1), paddi...\u001b[0m\n","\n","  File \"\u001b[32m/root/YOLOX/yolox/models/\u001b[0m\u001b[32m\u001b[1mnetwork_blocks.py\u001b[0m\", line \u001b[33m210\u001b[0m, in \u001b[35mforward\u001b[0m\n","    \u001b[35m\u001b[1mreturn\u001b[0m \u001b[1mself\u001b[0m\u001b[35m\u001b[1m.\u001b[0m\u001b[1mconv\u001b[0m\u001b[1m(\u001b[0m\u001b[1mx\u001b[0m\u001b[1m)\u001b[0m\n","    \u001b[36m       │         └ \u001b[0m\u001b[36m\u001b[1mtensor([[[[ 56.,  56.,  56.,  ..., 139., 139., 138.],\u001b[0m\n","    \u001b[36m       │           \u001b[0m\u001b[36m\u001b[1m          [ 56.,  56.,  56.,  ..., 143., 143., 142.],\u001b[0m\n","    \u001b[36m       │           \u001b[0m\u001b[36m\u001b[1m          [ 56., ...\u001b[0m\n","    \u001b[36m       └ \u001b[0m\u001b[36m\u001b[1mFocus(\u001b[0m\n","    \u001b[36m         \u001b[0m\u001b[36m\u001b[1m  (conv): BaseConv(\u001b[0m\n","    \u001b[36m         \u001b[0m\u001b[36m\u001b[1m    (conv): Conv2d(12, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\u001b[0m\n","    \u001b[36m         \u001b[0m\u001b[36m\u001b[1m    (bn)...\u001b[0m\n","\n","  File \"\u001b[32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/\u001b[0m\u001b[32m\u001b[1mmodule.py\u001b[0m\", line \u001b[33m1190\u001b[0m, in \u001b[35m_call_impl\u001b[0m\n","    \u001b[35m\u001b[1mreturn\u001b[0m \u001b[1mforward_call\u001b[0m\u001b[1m(\u001b[0m\u001b[35m\u001b[1m*\u001b[0m\u001b[1minput\u001b[0m\u001b[1m,\u001b[0m \u001b[35m\u001b[1m**\u001b[0m\u001b[1mkwargs\u001b[0m\u001b[1m)\u001b[0m\n","    \u001b[36m       │             │        └ \u001b[0m\u001b[36m\u001b[1m{}\u001b[0m\n","    \u001b[36m       │             └ \u001b[0m\u001b[36m\u001b[1m(tensor([[[[ 56.,  56.,  56.,  ..., 139., 139., 138.],\u001b[0m\n","    \u001b[36m       │               \u001b[0m\u001b[36m\u001b[1m          [ 56.,  56.,  56.,  ..., 143., 143., 142.],\u001b[0m\n","    \u001b[36m       │               \u001b[0m\u001b[36m\u001b[1m          [ 56.,...\u001b[0m\n","    \u001b[36m       └ \u001b[0m\u001b[36m\u001b[1m<bound method BaseConv.forward of BaseConv(\u001b[0m\n","    \u001b[36m         \u001b[0m\u001b[36m\u001b[1m  (conv): Conv2d(12, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=...\u001b[0m\n","\n","  File \"\u001b[32m/root/YOLOX/yolox/models/\u001b[0m\u001b[32m\u001b[1mnetwork_blocks.py\u001b[0m\", line \u001b[33m51\u001b[0m, in \u001b[35mforward\u001b[0m\n","    \u001b[35m\u001b[1mreturn\u001b[0m \u001b[1mself\u001b[0m\u001b[35m\u001b[1m.\u001b[0m\u001b[1mact\u001b[0m\u001b[1m(\u001b[0m\u001b[1mself\u001b[0m\u001b[35m\u001b[1m.\u001b[0m\u001b[1mbn\u001b[0m\u001b[1m(\u001b[0m\u001b[1mself\u001b[0m\u001b[35m\u001b[1m.\u001b[0m\u001b[1mconv\u001b[0m\u001b[1m(\u001b[0m\u001b[1mx\u001b[0m\u001b[1m)\u001b[0m\u001b[1m)\u001b[0m\u001b[1m)\u001b[0m\n","    \u001b[36m       │        │       │         └ \u001b[0m\u001b[36m\u001b[1mtensor([[[[ 56.,  56.,  56.,  ..., 139., 139., 138.],\u001b[0m\n","    \u001b[36m       │        │       │           \u001b[0m\u001b[36m\u001b[1m          [ 56.,  56.,  56.,  ..., 143., 143., 142.],\u001b[0m\n","    \u001b[36m       │        │       │           \u001b[0m\u001b[36m\u001b[1m          [ 56., ...\u001b[0m\n","    \u001b[36m       │        │       └ \u001b[0m\u001b[36m\u001b[1mBaseConv(\u001b[0m\n","    \u001b[36m       │        │         \u001b[0m\u001b[36m\u001b[1m  (conv): Conv2d(12, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\u001b[0m\n","    \u001b[36m       │        │         \u001b[0m\u001b[36m\u001b[1m  (bn): BatchNorm2d(32, eps...\u001b[0m\n","    \u001b[36m       │        └ \u001b[0m\u001b[36m\u001b[1mBaseConv(\u001b[0m\n","    \u001b[36m       │          \u001b[0m\u001b[36m\u001b[1m  (conv): Conv2d(12, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\u001b[0m\n","    \u001b[36m       │          \u001b[0m\u001b[36m\u001b[1m  (bn): BatchNorm2d(32, eps...\u001b[0m\n","    \u001b[36m       └ \u001b[0m\u001b[36m\u001b[1mBaseConv(\u001b[0m\n","    \u001b[36m         \u001b[0m\u001b[36m\u001b[1m  (conv): Conv2d(12, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\u001b[0m\n","    \u001b[36m         \u001b[0m\u001b[36m\u001b[1m  (bn): BatchNorm2d(32, eps...\u001b[0m\n","\n","  File \"\u001b[32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/\u001b[0m\u001b[32m\u001b[1mmodule.py\u001b[0m\", line \u001b[33m1190\u001b[0m, in \u001b[35m_call_impl\u001b[0m\n","    \u001b[35m\u001b[1mreturn\u001b[0m \u001b[1mforward_call\u001b[0m\u001b[1m(\u001b[0m\u001b[35m\u001b[1m*\u001b[0m\u001b[1minput\u001b[0m\u001b[1m,\u001b[0m \u001b[35m\u001b[1m**\u001b[0m\u001b[1mkwargs\u001b[0m\u001b[1m)\u001b[0m\n","    \u001b[36m       │             │        └ \u001b[0m\u001b[36m\u001b[1m{}\u001b[0m\n","    \u001b[36m       │             └ \u001b[0m\u001b[36m\u001b[1m(tensor([[[[ 56.,  56.,  56.,  ..., 139., 139., 138.],\u001b[0m\n","    \u001b[36m       │               \u001b[0m\u001b[36m\u001b[1m          [ 56.,  56.,  56.,  ..., 143., 143., 142.],\u001b[0m\n","    \u001b[36m       │               \u001b[0m\u001b[36m\u001b[1m          [ 56.,...\u001b[0m\n","    \u001b[36m       └ \u001b[0m\u001b[36m\u001b[1m<bound method Conv2d.forward of Conv2d(12, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)>\u001b[0m\n","\n","  File \"\u001b[32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/\u001b[0m\u001b[32m\u001b[1mconv.py\u001b[0m\", line \u001b[33m463\u001b[0m, in \u001b[35mforward\u001b[0m\n","    \u001b[35m\u001b[1mreturn\u001b[0m \u001b[1mself\u001b[0m\u001b[35m\u001b[1m.\u001b[0m\u001b[1m_conv_forward\u001b[0m\u001b[1m(\u001b[0m\u001b[1minput\u001b[0m\u001b[1m,\u001b[0m \u001b[1mself\u001b[0m\u001b[35m\u001b[1m.\u001b[0m\u001b[1mweight\u001b[0m\u001b[1m,\u001b[0m \u001b[1mself\u001b[0m\u001b[35m\u001b[1m.\u001b[0m\u001b[1mbias\u001b[0m\u001b[1m)\u001b[0m\n","    \u001b[36m       │    │             │      │            └ \u001b[0m\u001b[36m\u001b[1mConv2d(12, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\u001b[0m\n","    \u001b[36m       │    │             │      └ \u001b[0m\u001b[36m\u001b[1mConv2d(12, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\u001b[0m\n","    \u001b[36m       │    │             └ \u001b[0m\u001b[36m\u001b[1mtensor([[[[ 56.,  56.,  56.,  ..., 139., 139., 138.],\u001b[0m\n","    \u001b[36m       │    │               \u001b[0m\u001b[36m\u001b[1m          [ 56.,  56.,  56.,  ..., 143., 143., 142.],\u001b[0m\n","    \u001b[36m       │    │               \u001b[0m\u001b[36m\u001b[1m          [ 56., ...\u001b[0m\n","    \u001b[36m       │    └ \u001b[0m\u001b[36m\u001b[1m<function Conv2d._conv_forward at 0x7f610ef24310>\u001b[0m\n","    \u001b[36m       └ \u001b[0m\u001b[36m\u001b[1mConv2d(12, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\u001b[0m\n","\n","  File \"\u001b[32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/\u001b[0m\u001b[32m\u001b[1mconv.py\u001b[0m\", line \u001b[33m459\u001b[0m, in \u001b[35m_conv_forward\u001b[0m\n","    \u001b[35m\u001b[1mreturn\u001b[0m \u001b[1mF\u001b[0m\u001b[35m\u001b[1m.\u001b[0m\u001b[1mconv2d\u001b[0m\u001b[1m(\u001b[0m\u001b[1minput\u001b[0m\u001b[1m,\u001b[0m \u001b[1mweight\u001b[0m\u001b[1m,\u001b[0m \u001b[1mbias\u001b[0m\u001b[1m,\u001b[0m \u001b[1mself\u001b[0m\u001b[35m\u001b[1m.\u001b[0m\u001b[1mstride\u001b[0m\u001b[1m,\u001b[0m\n","    \u001b[36m       │ │      │      │       │     │    └ \u001b[0m\u001b[36m\u001b[1m(1, 1)\u001b[0m\n","    \u001b[36m       │ │      │      │       │     └ \u001b[0m\u001b[36m\u001b[1mConv2d(12, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\u001b[0m\n","    \u001b[36m       │ │      │      │       └ \u001b[0m\u001b[36m\u001b[1mNone\u001b[0m\n","    \u001b[36m       │ │      │      └ \u001b[0m\u001b[36m\u001b[1mParameter containing:\u001b[0m\n","    \u001b[36m       │ │      │        \u001b[0m\u001b[36m\u001b[1mtensor([[[[ 1.7095e-02,  2.7756e-02, -4.5178e-02],\u001b[0m\n","    \u001b[36m       │ │      │        \u001b[0m\u001b[36m\u001b[1m          [ 1.6555e-01,  1.8347e-01, -1.4731e-01],\u001b[0m\n","    \u001b[36m       │ │      │        \u001b[0m\u001b[36m\u001b[1m ...\u001b[0m\n","    \u001b[36m       │ │      └ \u001b[0m\u001b[36m\u001b[1mtensor([[[[ 56.,  56.,  56.,  ..., 139., 139., 138.],\u001b[0m\n","    \u001b[36m       │ │        \u001b[0m\u001b[36m\u001b[1m          [ 56.,  56.,  56.,  ..., 143., 143., 142.],\u001b[0m\n","    \u001b[36m       │ │        \u001b[0m\u001b[36m\u001b[1m          [ 56., ...\u001b[0m\n","    \u001b[36m       │ └ \u001b[0m\u001b[36m\u001b[1m<built-in method conv2d of type object at 0x7f617c62a980>\u001b[0m\n","    \u001b[36m       └ \u001b[0m\u001b[36m\u001b[1m<module 'torch.nn.functional' from '/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py'>\u001b[0m\n","\n","\u001b[31m\u001b[1mRuntimeError\u001b[0m:\u001b[1m cuDNN error: CUDNN_STATUS_INTERNAL_ERROR\n","You can try to repro this exception using the following code snippet. If that doesn't trigger the error, please include your original repro script when reporting this issue.\n","\n","import torch\n","torch.backends.cuda.matmul.allow_tf32 = False\n","torch.backends.cudnn.benchmark = True\n","torch.backends.cudnn.deterministic = False\n","torch.backends.cudnn.allow_tf32 = True\n","data = torch.randn([1, 12, 320, 320], dtype=torch.half, device='cuda', requires_grad=True)\n","net = torch.nn.Conv2d(12, 32, kernel_size=[3, 3], padding=[1, 1], stride=[1, 1], dilation=[1, 1], groups=1)\n","net = net.cuda().half()\n","out = net(data)\n","out.backward(torch.randn_like(out))\n","torch.cuda.synchronize()\n","\n","ConvolutionParams \n","    memory_format = Contiguous\n","    data_type = CUDNN_DATA_HALF\n","    padding = [1, 1, 0]\n","    stride = [1, 1, 0]\n","    dilation = [1, 1, 0]\n","    groups = 1\n","    deterministic = false\n","    allow_tf32 = true\n","input: TensorDescriptor 0x824a3a70\n","    type = CUDNN_DATA_HALF\n","    nbDims = 4\n","    dimA = 1, 12, 320, 320, \n","    strideA = 1228800, 102400, 320, 1, \n","output: TensorDescriptor 0x83cfcd90\n","    type = CUDNN_DATA_HALF\n","    nbDims = 4\n","    dimA = 1, 32, 320, 320, \n","    strideA = 3276800, 102400, 320, 1, \n","weight: FilterDescriptor 0x8532a670\n","    type = CUDNN_DATA_HALF\n","    tensor_format = CUDNN_TENSOR_NCHW\n","    nbDims = 4\n","    dimA = 32, 12, 3, 3, \n","Pointer addresses: \n","    input: 0x7f6072f18000\n","    output: 0x7f6073170000\n","    weight: 0x7f60739fe200\n","\u001b[0m\n"]}],"source":["!python /root/YOLOX/tools/train.py \\\n","    -f /root/YOLOX/yolox_s.py \\\n","    -d 2 \\\n","    -b 2 \\\n","    --fp16 \\\n","    -o \\\n","    -c /root/YOLOX/yolox_s.pth"]},{"cell_type":"markdown","metadata":{"id":"mmlvTpsheyQm"},"source":["# 推論テスト(Inference test)"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":54,"status":"ok","timestamp":1670589058318,"user":{"displayName":"みまみま","userId":"08438286750981985853"},"user_tz":-540},"id":"7hz1AF1jrXJg","outputId":"4d75b46d-e5f3-413f-e882-51cbcb275e82"},"outputs":[{"name":"stdout","output_type":"stream","text":["/root/YOLOX/tools\n"]}],"source":["%cd /root/YOLOX/tools"]},{"cell_type":"code","execution_count":41,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1670589058318,"user":{"displayName":"みまみま","userId":"08438286750981985853"},"user_tz":-540},"id":"vK8Ikghepwnw","outputId":"1e09626c-1686-4d18-824b-8cb65cc4a5bd"},"outputs":[{"name":"stdout","output_type":"stream","text":["Overwriting demo.py\n"]}],"source":["%%writefile demo.py\n","#!/usr/bin/env python3\n","# -*- coding:utf-8 -*-\n","# Copyright (c) Megvii, Inc. and its affiliates.\n","\n","import argparse\n","import os\n","import time\n","from loguru import logger\n","\n","import cv2\n","\n","import torch\n","\n","from yolox.data.data_augment import ValTransform\n","#from yolox.data.datasets import COCO_CLASSES #ここをコメントアウト\n","from yolox.exp import get_exp\n","from yolox.utils import fuse_model, get_model_info, postprocess, vis\n","\n","COCO_CLASSES = ('back','front') #ここに追記\n","\n","IMAGE_EXT = [\".jpg\", \".jpeg\", \".webp\", \".bmp\", \".png\"]\n","\n","\n","def make_parser():\n","    parser = argparse.ArgumentParser(\"YOLOX Demo!\")\n","    parser.add_argument(\n","        \"demo\", default=\"image\", help=\"demo type, eg. image, video and webcam\"\n","    )\n","    parser.add_argument(\"-expn\", \"--experiment-name\", type=str, default=None)\n","    parser.add_argument(\"-n\", \"--name\", type=str, default=None, help=\"model name\")\n","\n","    parser.add_argument(\n","        \"--path\", default=\"./assets/dog.jpg\", help=\"path to images or video\"\n","    )\n","    parser.add_argument(\"--camid\", type=int, default=0, help=\"webcam demo camera id\")\n","    parser.add_argument(\n","        \"--save_result\",\n","        action=\"store_true\",\n","        help=\"whether to save the inference result of image/video\",\n","    )\n","\n","    # exp file\n","    parser.add_argument(\n","        \"-f\",\n","        \"--exp_file\",\n","        default=None,\n","        type=str,\n","        help=\"please input your experiment description file\",\n","    )\n","    parser.add_argument(\"-c\", \"--ckpt\", default=None, type=str, help=\"ckpt for eval\")\n","    parser.add_argument(\n","        \"--device\",\n","        default=\"cpu\",\n","        type=str,\n","        help=\"device to run our model, can either be cpu or gpu\",\n","    )\n","    parser.add_argument(\"--conf\", default=0.3, type=float, help=\"test conf\")\n","    parser.add_argument(\"--nms\", default=0.3, type=float, help=\"test nms threshold\")\n","    parser.add_argument(\"--tsize\", default=None, type=int, help=\"test img size\")\n","    parser.add_argument(\n","        \"--fp16\",\n","        dest=\"fp16\",\n","        default=False,\n","        action=\"store_true\",\n","        help=\"Adopting mix precision evaluating.\",\n","    )\n","    parser.add_argument(\n","        \"--legacy\",\n","        dest=\"legacy\",\n","        default=False,\n","        action=\"store_true\",\n","        help=\"To be compatible with older versions\",\n","    )\n","    parser.add_argument(\n","        \"--fuse\",\n","        dest=\"fuse\",\n","        default=False,\n","        action=\"store_true\",\n","        help=\"Fuse conv and bn for testing.\",\n","    )\n","    parser.add_argument(\n","        \"--trt\",\n","        dest=\"trt\",\n","        default=False,\n","        action=\"store_true\",\n","        help=\"Using TensorRT model for testing.\",\n","    )\n","    return parser\n","\n","\n","def get_image_list(path):\n","    image_names = []\n","    for maindir, subdir, file_name_list in os.walk(path):\n","        for filename in file_name_list:\n","            apath = os.path.join(maindir, filename)\n","            ext = os.path.splitext(apath)[1]\n","            if ext in IMAGE_EXT:\n","                image_names.append(apath)\n","    return image_names\n","\n","\n","class Predictor(object):\n","    def __init__(\n","        self,\n","        model,\n","        exp,\n","        cls_names=COCO_CLASSES,\n","        trt_file=None,\n","        decoder=None,\n","        device=\"cpu\",\n","        fp16=False,\n","        legacy=False,\n","    ):\n","        self.model = model\n","        self.cls_names = cls_names\n","        self.decoder = decoder\n","        self.num_classes = exp.num_classes\n","        self.confthre = exp.test_conf\n","        self.nmsthre = exp.nmsthre\n","        self.test_size = exp.test_size\n","        self.device = device\n","        self.fp16 = fp16\n","        self.preproc = ValTransform(legacy=legacy)\n","        if trt_file is not None:\n","            from torch2trt import TRTModule\n","\n","            model_trt = TRTModule()\n","            model_trt.load_state_dict(torch.load(trt_file))\n","\n","            x = torch.ones(1, 3, exp.test_size[0], exp.test_size[1]).cuda()\n","            self.model(x)\n","            self.model = model_trt\n","\n","    def inference(self, img):\n","        img_info = {\"id\": 0}\n","        if isinstance(img, str):\n","            img_info[\"file_name\"] = os.path.basename(img)\n","            img = cv2.imread(img)\n","        else:\n","            img_info[\"file_name\"] = None\n","\n","        height, width = img.shape[:2]\n","        img_info[\"height\"] = height\n","        img_info[\"width\"] = width\n","        img_info[\"raw_img\"] = img\n","\n","        ratio = min(self.test_size[0] / img.shape[0], self.test_size[1] / img.shape[1])\n","        img_info[\"ratio\"] = ratio\n","\n","        img, _ = self.preproc(img, None, self.test_size)\n","        img = torch.from_numpy(img).unsqueeze(0)\n","        img = img.float()\n","        if self.device == \"gpu\":\n","            img = img.cuda()\n","            if self.fp16:\n","                img = img.half()  # to FP16\n","\n","        with torch.no_grad():\n","            t0 = time.time()\n","            outputs = self.model(img)\n","            if self.decoder is not None:\n","                outputs = self.decoder(outputs, dtype=outputs.type())\n","            outputs = postprocess(\n","                outputs, self.num_classes, self.confthre,\n","                self.nmsthre, class_agnostic=True\n","            )\n","            logger.info(\"Infer time: {:.4f}s\".format(time.time() - t0))\n","        return outputs, img_info\n","\n","    def visual(self, output, img_info, cls_conf=0.35):\n","        ratio = img_info[\"ratio\"]\n","        img = img_info[\"raw_img\"]\n","        if output is None:\n","            return img\n","        output = output.cpu()\n","\n","        bboxes = output[:, 0:4]\n","\n","        # preprocessing: resize\n","        bboxes /= ratio\n","\n","        cls = output[:, 6]\n","        scores = output[:, 4] * output[:, 5]\n","\n","        vis_res = vis(img, bboxes, scores, cls, cls_conf, self.cls_names)\n","        return vis_res\n","\n","\n","def image_demo(predictor, vis_folder, path, current_time, save_result):\n","    if os.path.isdir(path):\n","        files = get_image_list(path)\n","    else:\n","        files = [path]\n","    files.sort()\n","    for image_name in files:\n","        outputs, img_info = predictor.inference(image_name)\n","        result_image = predictor.visual(outputs[0], img_info, predictor.confthre)\n","        if save_result:\n","            save_folder = os.path.join(\n","                vis_folder, time.strftime(\"%Y_%m_%d_%H_%M_%S\", current_time)\n","            )\n","            os.makedirs(save_folder, exist_ok=True)\n","            save_file_name = os.path.join(save_folder, os.path.basename(image_name))\n","            logger.info(\"Saving detection result in {}\".format(save_file_name))\n","            cv2.imwrite(save_file_name, result_image)\n","        ch = cv2.waitKey(0)\n","        if ch == 27 or ch == ord(\"q\") or ch == ord(\"Q\"):\n","            break\n","\n","\n","def imageflow_demo(predictor, vis_folder, current_time, args):\n","    cap = cv2.VideoCapture(args.path if args.demo == \"video\" else args.camid)\n","    width = cap.get(cv2.CAP_PROP_FRAME_WIDTH)  # float\n","    height = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)  # float\n","    fps = cap.get(cv2.CAP_PROP_FPS)\n","    if args.save_result:\n","        save_folder = os.path.join(\n","            vis_folder, time.strftime(\"%Y_%m_%d_%H_%M_%S\", current_time)\n","        )\n","        os.makedirs(save_folder, exist_ok=True)\n","        if args.demo == \"video\":\n","            save_path = os.path.join(save_folder, os.path.basename(args.path))\n","        else:\n","            save_path = os.path.join(save_folder, \"camera.mp4\")\n","        logger.info(f\"video save_path is {save_path}\")\n","        vid_writer = cv2.VideoWriter(\n","            save_path, cv2.VideoWriter_fourcc(*\"mp4v\"), fps, (int(width), int(height))\n","        )\n","    while True:\n","        ret_val, frame = cap.read()\n","        if ret_val:\n","            outputs, img_info = predictor.inference(frame)\n","            result_frame = predictor.visual(outputs[0], img_info, predictor.confthre)\n","            if args.save_result:\n","                vid_writer.write(result_frame)\n","            else:\n","                cv2.namedWindow(\"yolox\", cv2.WINDOW_NORMAL)\n","                cv2.imshow(\"yolox\", result_frame)\n","            ch = cv2.waitKey(1)\n","            if ch == 27 or ch == ord(\"q\") or ch == ord(\"Q\"):\n","                break\n","        else:\n","            break\n","\n","\n","def main(exp, args):\n","    if not args.experiment_name:\n","        args.experiment_name = exp.exp_name\n","\n","    file_name = os.path.join(exp.output_dir, args.experiment_name)\n","    os.makedirs(file_name, exist_ok=True)\n","\n","    vis_folder = None\n","    if args.save_result:\n","        vis_folder = os.path.join(file_name, \"vis_res\")\n","        os.makedirs(vis_folder, exist_ok=True)\n","\n","    if args.trt:\n","        args.device = \"gpu\"\n","\n","    logger.info(\"Args: {}\".format(args))\n","\n","    if args.conf is not None:\n","        exp.test_conf = args.conf\n","    if args.nms is not None:\n","        exp.nmsthre = args.nms\n","    if args.tsize is not None:\n","        exp.test_size = (args.tsize, args.tsize)\n","\n","    model = exp.get_model()\n","    logger.info(\"Model Summary: {}\".format(get_model_info(model, exp.test_size)))\n","\n","    if args.device == \"gpu\":\n","        model.cuda()\n","        if args.fp16:\n","            model.half()  # to FP16\n","    model.eval()\n","\n","    if not args.trt:\n","        if args.ckpt is None:\n","            ckpt_file = os.path.join(file_name, \"best_ckpt.pth\")\n","        else:\n","            ckpt_file = args.ckpt\n","        logger.info(\"loading checkpoint\")\n","        ckpt = torch.load(ckpt_file, map_location=\"cpu\")\n","        # load the model state dict\n","        model.load_state_dict(ckpt[\"model\"])\n","        logger.info(\"loaded checkpoint done.\")\n","\n","    if args.fuse:\n","        logger.info(\"\\tFusing model...\")\n","        model = fuse_model(model)\n","\n","    if args.trt:\n","        assert not args.fuse, \"TensorRT model is not support model fusing!\"\n","        trt_file = os.path.join(file_name, \"model_trt.pth\")\n","        assert os.path.exists(\n","            trt_file\n","        ), \"TensorRT model is not found!\\n Run python3 tools/trt.py first!\"\n","        model.head.decode_in_inference = False\n","        decoder = model.head.decode_outputs\n","        logger.info(\"Using TensorRT to inference\")\n","    else:\n","        trt_file = None\n","        decoder = None\n","\n","    predictor = Predictor(\n","        model, exp, COCO_CLASSES, trt_file, decoder,\n","        args.device, args.fp16, args.legacy,\n","    )\n","    current_time = time.localtime()\n","    if args.demo == \"image\":\n","        image_demo(predictor, vis_folder, args.path, current_time, args.save_result)\n","    elif args.demo == \"video\" or args.demo == \"webcam\":\n","        imageflow_demo(predictor, vis_folder, current_time, args)\n","\n","\n","if __name__ == \"__main__\":\n","    args = make_parser().parse_args()\n","    exp = get_exp(args.exp_file, args.name)\n","\n","    main(exp, args)"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1670589058319,"user":{"displayName":"みまみま","userId":"08438286750981985853"},"user_tz":-540},"id":"wUWDMRpPrjSM","outputId":"2e173532-d0b6-4149-d711-27ec3ee18c5c"},"outputs":[{"name":"stdout","output_type":"stream","text":["/root\n"]}],"source":["%cd /root"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8039,"status":"ok","timestamp":1670589289114,"user":{"displayName":"みまみま","userId":"08438286750981985853"},"user_tz":-540},"id":"w3g0ZRUwMP8k","outputId":"d349269e-653b-4b7d-be2d-7ab362b7da6a"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[32m2022-12-26 20:54:09.248\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m261\u001b[0m - \u001b[1mArgs: Namespace(camid=0, ckpt='/root/YOLOX/YOLOX_outputs/yolox_s/best_ckpt.pth', conf=0.25, demo='image', device='gpu', exp_file='yolox_s.py', experiment_name='yolox_s', fp16=False, fuse=False, legacy=False, name=None, nms=0.45, path='/root/TestImages/南西v3.jpg', save_result=True, trt=False, tsize=416)\u001b[0m\n","\u001b[32m2022-12-26 20:54:09.378\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m271\u001b[0m - \u001b[1mModel Summary: Params: 8.94M, Gflops: 11.31\u001b[0m\n","\u001b[32m2022-12-26 20:54:10.516\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m284\u001b[0m - \u001b[1mloading checkpoint\u001b[0m\n","\u001b[32m2022-12-26 20:54:10.585\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m288\u001b[0m - \u001b[1mloaded checkpoint done.\u001b[0m\n","\u001b[32m2022-12-26 20:54:11.733\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36minference\u001b[0m:\u001b[36m167\u001b[0m - \u001b[1mInfer time: 1.0142s\u001b[0m\n","\u001b[32m2022-12-26 20:54:11.735\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mimage_demo\u001b[0m:\u001b[36m204\u001b[0m - \u001b[1mSaving detection result in ./YOLOX_outputs/yolox_s/vis_res/2022_12_26_20_54_10/南西v3.jpg\u001b[0m\n"]}],"source":["TEST_IMAGE_PATH = \"/root/TestImages/南西v3.jpg\"\n","MODEL_PATH = \"/root/YOLOX/YOLOX_outputs/yolox_s/best_ckpt.pth\"\n","\n","!python tools/demo.py image \\\n","    -f yolox_s.py \\\n","    -c {MODEL_PATH} \\\n","    --path {TEST_IMAGE_PATH} \\\n","    --conf 0.25 \\\n","    --nms 0.45 \\\n","    --tsize 416 \\\n","    --save_result \\\n","    --device gpu"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":488,"output_embedded_package_id":"17P5uaIcQDFjaVPZbBQoWAmHrOX8Ws-9V"},"executionInfo":{"elapsed":11462,"status":"ok","timestamp":1670589321374,"user":{"displayName":"みまみま","userId":"08438286750981985853"},"user_tz":-540},"id":"67bW5EWTtUA-","outputId":"4377084e-3e01-4673-9f31-5922ab58042e"},"outputs":[],"source":["import cv2\n","\n","OUTPUT_IMAGE_PATH = \"/root/YOLOX/YOLOX_outputs/yolox_s/vis_res/2022_12_23_20_07_28/南西v3.jpg\" \n","\n","debug_image = cv2.imread(OUTPUT_IMAGE_PATH)\n","\n","#imres= cv2.resize(debug_image, dsize=(960, 540))\n","\n","\"\"\"height = debug_image.shape[0]\n","width = debug_image.shape[1]\n","resized_image = cv2.resize(debug_image, (width/2, height/2))\"\"\"\n","\n","cv2.imshow('Folk', debug_image)\n","cv2.waitKey(0)\n","cv2.destroyAllWindows()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XL-oSdFrg0Pb"},"outputs":[],"source":["# from PIL import Image\n","\n","# OUTPUT_IMAGE_PATH = \"/content/YOLOX/YOLOX_outputs/nano/vis_res/2021_09_29_17_46_56/000050.jpg\" \n","# Image.open(OUTPUT_IMAGE_PATH)"]},{"cell_type":"markdown","metadata":{"id":"XT2WBgo7jAvR"},"source":["# ONNX出力(Export ONNX Model)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5883,"status":"ok","timestamp":1670589075815,"user":{"displayName":"みまみま","userId":"08438286750981985853"},"user_tz":-540},"id":"vHpT0bQBhHzt","outputId":"ff06af91-fca5-43ef-b443-608afa809545"},"outputs":[],"source":["!python tools/export_onnx.py \\\n","    --output-name yolox_s.onnx \\\n","    -n yolox-s \\\n","    -f yolox_s.py \\\n","    -c {MODEL_PATH}"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":41,"status":"ok","timestamp":1670589075815,"user":{"displayName":"みまみま","userId":"08438286750981985853"},"user_tz":-540},"id":"ESOnydCZNxAd","outputId":"d4eb8a7a-bb65-4f64-a4d4-f141a0c5d819"},"outputs":[],"source":["%%writefile onnx_inference.py\n","#!/usr/bin/env python3\n","# -*- coding: utf-8 -*-\n","# Copyright (c) Megvii, Inc. and its affiliates.\n","\n","import argparse\n","import os\n","\n","import cv2\n","import numpy as np\n","\n","import onnxruntime\n","\n","from yolox.data.data_augment import preproc as preprocess\n","#from yolox.data.datasets import COCO_CLASSES\n","from yolox.utils import mkdir, multiclass_nms, demo_postprocess, vis\n","\n","COCO_CLASSES = ('back','front') #ここに追記\n","\n","\n","def make_parser():\n","    parser = argparse.ArgumentParser(\"onnxruntime inference sample\")\n","    parser.add_argument(\n","        \"-m\",\n","        \"--model\",\n","        type=str,\n","        default=\"yolox.onnx\",\n","        help=\"Input your onnx model.\",\n","    )\n","    parser.add_argument(\n","        \"-i\",\n","        \"--image_path\",\n","        type=str,\n","        default='test_image.png',\n","        help=\"Path to your input image.\",\n","    )\n","    parser.add_argument(\n","        \"-o\",\n","        \"--output_dir\",\n","        type=str,\n","        default='demo_output',\n","        help=\"Path to your output directory.\",\n","    )\n","    parser.add_argument(\n","        \"-s\",\n","        \"--score_thr\",\n","        type=float,\n","        default=0.3,\n","        help=\"Score threshould to filter the result.\",\n","    )\n","    parser.add_argument(\n","        \"--input_shape\",\n","        type=str,\n","        default=\"640,640\",\n","        help=\"Specify an input shape for inference.\",\n","    )\n","    parser.add_argument(\n","        \"--with_p6\",\n","        action=\"store_true\",\n","        help=\"Whether your model uses p6 in FPN/PAN.\",\n","    )\n","    return parser\n","\n","\n","if __name__ == '__main__':\n","    args = make_parser().parse_args()\n","\n","    input_shape = tuple(map(int, args.input_shape.split(',')))\n","    origin_img = cv2.imread(args.image_path)\n","    img, ratio = preprocess(origin_img, input_shape)\n","\n","    session = onnxruntime.InferenceSession(args.model)\n","\n","    ort_inputs = {session.get_inputs()[0].name: img[None, :, :, :]}\n","    output = session.run(None, ort_inputs)\n","    predictions = demo_postprocess(output[0], input_shape, p6=args.with_p6)[0]\n","\n","    boxes = predictions[:, :4]\n","    scores = predictions[:, 4:5] * predictions[:, 5:]\n","\n","    boxes_xyxy = np.ones_like(boxes)\n","    boxes_xyxy[:, 0] = boxes[:, 0] - boxes[:, 2]/2.\n","    boxes_xyxy[:, 1] = boxes[:, 1] - boxes[:, 3]/2.\n","    boxes_xyxy[:, 2] = boxes[:, 0] + boxes[:, 2]/2.\n","    boxes_xyxy[:, 3] = boxes[:, 1] + boxes[:, 3]/2.\n","    boxes_xyxy /= ratio\n","    dets = multiclass_nms(boxes_xyxy, scores, nms_thr=0.45, score_thr=0.1)\n","    if dets is not None:\n","        final_boxes, final_scores, final_cls_inds = dets[:, :4], dets[:, 4], dets[:, 5]\n","        origin_img = vis(origin_img, final_boxes, final_scores, final_cls_inds,\n","                         conf=args.score_thr, class_names=COCO_CLASSES)\n","\n","    mkdir(args.output_dir)\n","    output_path = os.path.join(args.output_dir, os.path.basename(args.image_path))\n","    cv2.imwrite(output_path, origin_img)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Wc9dkeMh6QXr"},"outputs":[],"source":["TEST_IMAGE_PATH = \"/content/drive/MyDrive/TestImages/南西v3.jpg\""]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":2922,"status":"ok","timestamp":1670589363784,"user":{"displayName":"みまみま","userId":"08438286750981985853"},"user_tz":-540},"id":"q501MZh_jkIv"},"outputs":[],"source":["!python onnx_inference.py \\\n","    -m yolox_s.onnx \\\n","    -i {TEST_IMAGE_PATH} \\\n","    -o ./ \\\n","    -s 0.3 \\\n","    --input_shape 640,640"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":488,"output_embedded_package_id":"1fAon0XgvUjg2MJvFAd_oi7VidUAZTPSo"},"executionInfo":{"elapsed":11658,"status":"ok","timestamp":1670589379000,"user":{"displayName":"みまみま","userId":"08438286750981985853"},"user_tz":-540},"id":"uwcQysS_j_yp","outputId":"fddf8ad3-2cd9-4ba2-cde0-c19d16586c7b"},"outputs":[],"source":["from PIL import Image\n","\n","OUTPUT_IMAGE_PATH = \"南西v3.jpg\" \n","Image.open(OUTPUT_IMAGE_PATH)"]},{"cell_type":"markdown","metadata":{"id":"07vb6wwhEAzL"},"source":["# ONNXでバウンディングボックス取得"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":1701,"status":"ok","timestamp":1670589431215,"user":{"displayName":"みまみま","userId":"08438286750981985853"},"user_tz":-540},"id":"Y1C79iH7Fxnm"},"outputs":[],"source":["import argparse\n","import os\n","import cv2\n","import numpy as np\n","import pandas as pd\n","import onnxruntime\n","from google.colab.patches import cv2_imshow\n","from yolox.data.data_augment import preproc as preprocess\n","#from yolox.data.datasets import COCO_CLASSES\n","from yolox.utils import mkdir, multiclass_nms, demo_postprocess, vis\n","\n","COCO_CLASSES = ('back','front') #ここに追記"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1265,"status":"ok","timestamp":1670589437191,"user":{"displayName":"みまみま","userId":"08438286750981985853"},"user_tz":-540},"id":"P6IIr64FEJOS","outputId":"b14994bd-d20d-4205-d4c6-095adb798732"},"outputs":[],"source":["output_dir ='onnx_out'\n","image_path = '/content/drive/MyDrive/TestImages/南西v3.jpg'\n","model = '/content/YOLOX/yolox_s.onnx'\n","    \n","input_shape = (640,640)\n","origin_img = cv2.imread(image_path)\n","img, ratio = preprocess(origin_img, input_shape)\n","session = onnxruntime.InferenceSession(model)\n","ort_inputs = {session.get_inputs()[0].name: img[None, :, :, :]}\n","output = session.run(None, ort_inputs)\n","predictions = demo_postprocess(output[0], input_shape)[0]\n","boxes = predictions[:, :4]\n","scores = predictions[:, 4:5] * predictions[:, 5:]\n","boxes_xyxy = np.ones_like(boxes)\n","boxes_xyxy[:, 0] = boxes[:, 0] - boxes[:, 2]/2.\n","boxes_xyxy[:, 1] = boxes[:, 1] - boxes[:, 3]/2.\n","boxes_xyxy[:, 2] = boxes[:, 0] + boxes[:, 2]/2.\n","boxes_xyxy[:, 3] = boxes[:, 1] + boxes[:, 3]/2.\n","boxes_xyxy /= ratio\n","dets = multiclass_nms(boxes_xyxy, scores, nms_thr=0.45, score_thr=0.5)\n","if dets is not None:\n","    final_boxes, final_scores, final_cls_inds = dets[:, :4], dets[:, 4], dets[:, 5]\n","    origin_img = vis(origin_img, final_boxes, final_scores, final_cls_inds,\n","                      0.3, class_names=COCO_CLASSES)\n","mkdir(output_dir)\n","output_path = os.path.join(output_dir, os.path.basename(image_path))\n","cv2.imwrite(output_path, origin_img)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":156},"executionInfo":{"elapsed":315,"status":"ok","timestamp":1670589441258,"user":{"displayName":"みまみま","userId":"08438286750981985853"},"user_tz":-540},"id":"mI3W4nbzG_41","outputId":"4968571b-11db-417d-c198-a72e97cf51d5"},"outputs":[],"source":["result = []\n","[result.extend((final_cls_inds[x],COCO_CLASSES[int(final_cls_inds[x])],final_scores[x],final_boxes[x][0],final_boxes[x][1],final_boxes[x][2],final_boxes[x][3]) for x in range(len(final_scores)))]\n","df = pd.DataFrame(result, columns = ['class-id','class','score','x-min','y-min','x-max','y-max'])\n","df"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":311,"status":"ok","timestamp":1670591155038,"user":{"displayName":"みまみま","userId":"08438286750981985853"},"user_tz":-540},"id":"vCbtijXZWRwU","outputId":"cf0e3048-d2d2-47a6-8f4e-22e1288460cb"},"outputs":[],"source":["backc_x = (final_boxes[0][2] + final_boxes[0][0]) / 2\n","backc_y = (final_boxes[0][3] + final_boxes[0][1]) / 2\n","\n","frontc_x = (final_boxes[1][2] + final_boxes[1][0]) / 2\n","frontc_y = (final_boxes[1][3] + final_boxes[1][1]) / 2\n","\n","print(backc_x, backc_y)\n","print(frontc_x, frontc_y)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1670668736037,"user":{"displayName":"みまみま","userId":"08438286750981985853"},"user_tz":-540},"id":"AW2nKLrKXMOC","outputId":"c34ef710-70c6-4956-bf84-282e93f49713"},"outputs":[],"source":["import math\n","backc_x = 3168.505859375\n","backc_y = 759.1664428710938\n","\n","frontc_x = 1213.4153442382812\n","frontc_y = 2583.9623413085938\n","\n","front = [frontc_x, frontc_y]\n","center_x = (backc_x + frontc_x) / 2 \n","center_y = (backc_y + frontc_y) / 2\n","center = [center_x, center_y]\n","\n","print(\"front =\", front)\n","print(\"center = \", center)\n","f_moved = [front[0] - center[0], front[1] - center[1]]\n","print(\"f_moved = \", f_moved)\n","\n","#rad = math.atan2(center_y - frontc_y , center_x - frontc_x)\n","rad = math.atan2(-(front[1] - center[1]), front[0] - center[0])\n","\n","\n","print(\"rad = \", rad)\n","\n","deg = rad * (180 / math.pi) \n","\n","print(\"deg =\", deg)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7314,"status":"ok","timestamp":1670660815953,"user":{"displayName":"みまみま","userId":"08438286750981985853"},"user_tz":-540},"id":"1SpHOZK9JLLa","outputId":"814264ef-93be-4d7f-8f8e-f60b74501733"},"outputs":[],"source":["!pip install japanize-matplotlib"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":397},"executionInfo":{"elapsed":445,"status":"ok","timestamp":1670676088224,"user":{"displayName":"みまみま","userId":"08438286750981985853"},"user_tz":-540},"id":"gw7E8xfkcDYn","outputId":"9c2622f4-14e6-4dd4-f50d-469841d02d6d"},"outputs":[],"source":["# python_visualize_vector_2d\n","\n","\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","\n","# 5×5サイズのFigureを作成してAxesを追加\n","fig = plt.figure(figsize = (6, 6))\n","ax = fig.add_subplot(111)\n","\n","# ベクトルを表示\n","# quiver(始点x,始点y,成分x,成分y)\n","ax.quiver(0, 0, f_moved[0], -f_moved[1], color = \"red\", #画像座標系->標準座標系にするためにyに-をつけて反転\n","          angles = 'xy', scale_units = 'xy', scale = 1) \n","\n","plt.scatter(0, 0, label='center') #始点\n","plt.scatter(f_moved[0], -f_moved[1], label='front') #終点\n","\n","\n","plt.legend() #凡例\n","\n","#plt.title('中点からフォーク先端への方向と角度', fontsize=20) #タイトル\n","\n","\n","# 格子点を表示\n","plt.grid()\n","\n","# 軸ラベルの設定\n","ax.set_xlabel(\"x\", fontsize = 16)\n","ax.set_ylabel(\"y\", fontsize = 16)\n","\n","# 軸範囲の設定\n","plt.xlim(-1500, 1500)\n","plt.ylim(-1500, 1500)\n","\n","# x軸とy軸\n","ax.axhline(0, color = \"gray\")\n","ax.axvline(0, color = \"gray\")\n","\n","\n","\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"pxuKKcgj6WND"},"source":["# ONNX -> TensorFlow 変換"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PKETcM79q3XD"},"outputs":[],"source":["!pip install onnx-tf"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EpiNXqOA6aoU"},"outputs":[],"source":["!onnx-tf convert \\\n","    -i yolox_nano.onnx \\\n","    -o yolox_nano_pb"]},{"cell_type":"markdown","metadata":{"id":"lV7E1wlX6cli"},"source":["# TensorFlow -> TensorFlow-Lite 変換"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-Aln_cLaN5G0"},"outputs":[],"source":["!pip install tf-nightly"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"H1zYkqM26alJ"},"outputs":[],"source":["import tensorflow as tf"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GI_X2zBhOSmw"},"outputs":[],"source":["%cd /content/YOLOX"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bdV9QUme-cD0"},"outputs":[],"source":["# ダイナミックレンジ量子化\n","converter = tf.lite.TFLiteConverter.from_saved_model('yolox_nano_pb')\n","converter.optimizations = [tf.lite.Optimize.DEFAULT]\n","tflite_quantized_model = converter.convert()\n","\n","open('yolox_nano_dynamic_range_quantize.tflite', 'wb').write(tflite_quantized_model)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3wgIUaj06aiV"},"outputs":[],"source":["# 半精度浮動小数点数の量子化\n","converter = tf.lite.TFLiteConverter.from_saved_model('yolox_nano_pb')\n","converter.optimizations = [tf.lite.Optimize.DEFAULT]\n","converter.target_spec.supported_types = [tf.float16]\n","tflite_quantized_model = converter.convert()\n","\n","open('yolox_nano_float16_quantize.tflite', 'wb').write(tflite_quantized_model)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZjmUxifw6aew"},"outputs":[],"source":["# 完全整数量子化\n","import glob\n","import numpy as np\n","from PIL import Image\n","\n","test_image_pathlist = glob.glob('/content/YOLOX-Colaboratory-Training-Sample/01.image/*.jpg')\n","test_image_pathlist = test_image_pathlist[:100]\n","print(len(test_image_pathlist))\n","\n","def representative_dataset():\n","    for test_image_path in test_image_pathlist:\n","        image = np.array(Image.open(test_image_path))\n","        image = image.astype('float32')\n","        image = tf.image.resize(image, (416, 416))\n","        image = image - 127.5\n","        image = image * 0.007843\n","        image = tf.transpose(image, perm=[2, 0, 1])\n","        image = tf.reshape(image, [1, 3, 416, 416])\n","        yield [image]\n","\n","converter = tf.lite.TFLiteConverter.from_saved_model('yolox_nano_pb')\n","converter.optimizations = [tf.lite.Optimize.DEFAULT]\n","converter.representative_dataset = representative_dataset\n","tflite_quantized_model = converter.convert()\n","\n","open('yolox_nano_int8_quantize.tflite', 'wb').write(tflite_quantized_model)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"y9cTtsmA6aaY"},"outputs":[],"source":["# 完全整数量子化(入力含む)\n","import glob\n","import numpy as np\n","from PIL import Image\n","\n","test_image_pathlist = glob.glob('/content/YOLOX-Colaboratory-Training-Sample/01.image/*.jpg')\n","test_image_pathlist = test_image_pathlist[:100]\n","print(len(test_image_pathlist))\n","\n","def representative_dataset():\n","    for test_image_path in test_image_pathlist:\n","        image = np.array(Image.open(test_image_path))\n","        image = image.astype('float32')\n","        image = tf.image.resize(image, (416, 416))\n","        image = image - 127.5\n","        image = image * 0.007843\n","        image = tf.transpose(image, perm=[2, 0, 1])\n","        image = tf.reshape(image, [1, 3, 416, 416])\n","        yield [image]\n","\n","converter = tf.lite.TFLiteConverter.from_saved_model('yolox_nano_pb')\n","converter.optimizations = [tf.lite.Optimize.DEFAULT]\n","converter.representative_dataset = representative_dataset\n","converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n","converter.inference_input_type = tf.int8  # or tf.uint8\n","converter.inference_output_type = tf.int8  # or tf.uint8\n","tflite_quantized_model = converter.convert()\n","\n","open('yolox_nano_only_int8_quantize.tflite', 'wb').write(tflite_quantized_model)"]}],"metadata":{"colab":{"collapsed_sections":["pxuKKcgj6WND","lV7E1wlX6cli"],"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"},"vscode":{"interpreter":{"hash":"e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"}}},"nbformat":4,"nbformat_minor":0}
